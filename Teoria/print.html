<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Teoria</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon-de23e50b.svg">
        <link rel="shortcut icon" href="favicon-8114d1fc.png">
        <link rel="stylesheet" href="css/variables-8adf115d.css">
        <link rel="stylesheet" href="css/general-2459343d.css">
        <link rel="stylesheet" href="css/chrome-ae938929.css">
        <link rel="stylesheet" href="css/print-9e4910d8.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="fonts/fonts-9644e21d.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="mdbook-highlight-css" href="highlight-493f70e1.css">
        <link rel="stylesheet" id="mdbook-tomorrow-night-css" href="tomorrow-night-4c0ae647.css">
        <link rel="stylesheet" id="mdbook-ayu-highlight-css" href="ayu-highlight-3fdfc3ac.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex-dfd27220.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc-ec27ba43.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="mdbook-body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="mdbook-sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("mdbook-sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="mdbook-sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="mdbook-sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="mdbook-page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="mdbook-menu-bar-hover-placeholder"></div>
                <div id="mdbook-menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="mdbook-sidebar-toggle" class="icon-button" for="mdbook-sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="mdbook-sidebar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"/></svg></span>
                        </label>
                        <button id="mdbook-theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="mdbook-theme-list">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M371.3 367.1c27.3-3.9 51.9-19.4 67.2-42.9L600.2 74.1c12.6-19.5 9.4-45.3-7.6-61.2S549.7-4.4 531.1 9.6L294.4 187.2c-24 18-38.2 46.1-38.4 76.1L371.3 367.1zm-19.6 25.4l-116-104.4C175.9 290.3 128 339.6 128 400c0 3.9 .2 7.8 .6 11.6c1.8 17.5-10.2 36.4-27.8 36.4H96c-17.7 0-32 14.3-32 32s14.3 32 32 32H240c61.9 0 112-50.1 112-112c0-2.5-.1-5-.2-7.5z"/></svg></span>
                        </button>
                        <ul id="mdbook-theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-ayu">Ayu</button></li>
                        </ul>
                        <button id="mdbook-search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="mdbook-searchbar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0S416 93.1 416 208zM208 352c79.5 0 144-64.5 144-144s-64.5-144-144-144S64 128.5 64 208s64.5 144 144 144z"/></svg></span>
                        </button>
                    </div>

                    <h1 class="menu-title">Teoria</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <span class=fa-svg id="print-button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M128 0C92.7 0 64 28.7 64 64v96h64V64H354.7L384 93.3V160h64V93.3c0-17-6.7-33.3-18.7-45.3L400 18.7C388 6.7 371.7 0 354.7 0H128zM384 352v32 64H128V384 368 352H384zm64 32h32c17.7 0 32-14.3 32-32V256c0-35.3-28.7-64-64-64H64c-35.3 0-64 28.7-64 64v96c0 17.7 14.3 32 32 32H64v64c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V384zm-16-88c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z"/></svg></span>
                        </a>

                    </div>
                </div>

                <div id="mdbook-search-wrapper" class="hidden">
                    <form id="mdbook-searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="mdbook-searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="mdbook-searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <span class=fa-svg id="fa-spin"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M304 48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zm0 416c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM48 304c26.5 0 48-21.5 48-48s-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48zm464-48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM142.9 437c18.7-18.7 18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zm0-294.2c18.7-18.7 18.7-49.1 0-67.9S93.7 56.2 75 75s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zM369.1 437c18.7 18.7 49.1 18.7 67.9 0s18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9z"/></svg></span>
                            </div>
                        </div>
                    </form>
                    <div id="mdbook-searchresults-outer" class="searchresults-outer hidden">
                        <div id="mdbook-searchresults-header" class="searchresults-header"></div>
                        <ul id="mdbook-searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('mdbook-sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('mdbook-sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#mdbook-sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="mdbook-content" class="content">
                    <main>
                        <script src="../javascript.js"></script>
<h1 id="architettura-di-un-so"><a class="header" href="#architettura-di-un-so">Architettura di un SO</a></h1>
<h2 id="funzionalità-di-un-so"><a class="header" href="#funzionalità-di-un-so">Funzionalità di un SO</a></h2>
<ul>
<li>
<p>Virtualizzazione delle risorse hardware</p>
<ul>
<li>file system</li>
<li>processi</li>
<li>periferiche astratte</li>
<li>…</li>
</ul>
<p>Sono tutti concetti che permette di ottenere una virtualizzazione e un’estensione delle risorse hardware della macchina fisica.</p>
<p>Oltre a creare un’astrazione per la macchina fisica, il SO fornisce anche un API di sistema che permette alle applicazioni utente di operare sull’hardware delegando le operazioni a quest’ultimo che interagisce direttamente con l’hardware.</p>
<p>Queste API garantiscono un accesso uniforme rispetto tutte le componenti hardware che possono essere anche molto eterogenee tra loro.</p>
</li>
<li>
<p>Gestione e coordinamento</p>
<p>Il SO ha il compito di arbitrare le richieste dei programmi utente</p>
<ul>
<li>meccanismi di protezione → per evitare azioni illecite da parte di processi malfunzionanti</li>
<li>meccanismi per la comunicazione inter-processo</li>
<li>gestore delle risorse → scheduling</li>
</ul>
</li>
</ul>
<p align="center"><img src="images/SO_come_VM.png" width="500"></p>

<ul>
<li>Tutti questi strati mi <strong>permettono di astrarre</strong> le risorse hardware le quali sono gestite direttamente dal Kernel, che fa da ultimo intermediario tra il livello software e quello hardware.</li>
<li>Quindi tutti gli strati che si contrappongono tra l’hardware e i programmi di utilità definiscono una <strong>macchina</strong> <strong>virtuale</strong>.</li>
<li>Tutti gli strati intermedi che definiscono un’astrazione potrebbero essere inclusi all’interno del Kernel, questo infatti dipende dall’architettura del SO.</li>
</ul>
<p>Ogni strato serve a nascondere la complessità dello strato sottostante e a fornire servizi più semplici e potenti allo strato superiore.</p>
<h2 id="kernel"><a class="header" href="#kernel">Kernel</a></h2>
<p>Il Kernel è quella parte del SO che risiede in memoria principale.</p>
<p>Contiene funzionalità fondamentali del SO.</p>
<p>A livello <strong>kernel</strong>, la macchina virtuale realizzata dal SO (dal punto di vista delle singole applicazioni utente):</p>
<ul>
<li>
<p>possiede tante unità centrali quanti sono i processi attivi nel sistema (ovvero processori virtuali).</p>
<p>Ogni processo ha l’illusione di avere per se un processore dedicato, indipendentemente dal numero reale di processori fisici;</p>
</li>
<li>
<p>non possiede meccanismi di interruzione. I processi vedono un flusso di esecuzione continuo e non devono gestire le interruzioni hardware perché sono intercettate dal kernel che provvede alla gestione;</p>
<p>questo è possibile per il context switch che viene fatto all’atto della sospensione del processo per la gestione da parte del SO delle interrupt. Nel momento in cui è terminata la ISR per gestire l’interrupt il processo torna ad eseguire sulla CPU partendo dallo stato in cui è stato sospeso.</p>
<p>Quindi per il processo la gestione delle interruzioni è trasparente.</p>
</li>
<li>
<p>possiede istruzioni di sincronizzazione e scambio di messaggi tra processi che operano su processori virtuali.</p>
<p>Tali meccanismi di sincronizzazione e scambio di messaggi avvengono tramite l’utilizzo di syscalls.</p>
</li>
</ul>
<h2 id="gestione-della-memoria"><a class="header" href="#gestione-della-memoria">Gestione della memoria</a></h2>
<p>A livello della <strong>gestione della memoria</strong>, la macchina virtuale realizzata dal SO (dal punto di vista dei processi):</p>
<ul>
<li>
<p>consente di far riferimento a <strong>spazi</strong> <strong>di</strong> <strong>indirizzamento</strong> <strong>virtuali</strong>.</p>
<p>Questi creano un’astrazione per i processi, illudendo questi di avere a disposizione l’intera memoria centrale per se.</p>
</li>
<li>
<p>gestisce la protezione, ovvero il gestore della memoria verifica che non ci siano interferenze tra i vari processi, quindi che lo spazio di indirizzamento del singolo processo sia isolato e non accessibili da altri processi.</p>
<p>Quindi due processi potrebbero utilizzare due indirizzi virtuali uguali ma questi saranno mappati in indirizzi fisici distinti nel momento il cui i processi andranno ad accedere a questi.</p>
</li>
<li>
<p>consente di rendere trasparente la posizione effettiva dei dati/istruzioni per i processi. Infatti i dati che un processo intende leggere e modificare possono risiedere temporaneamente in memoria di massa in casi particolari.</p>
<p>Questi casi particolari corrispondono ad esempio alla saturazione della memoria centrale. In tali casi alcune pagine vengono swappate in una porzione della memoria secondaria utilizzata per mantenere pagine della memoria centrale che non vengono subito utilizzate.</p>
</li>
</ul>
<h2 id="gestione-delle-periferiche"><a class="header" href="#gestione-delle-periferiche">Gestione delle periferiche</a></h2>
<p>Al livello <strong>gestione delle periferiche</strong>, la macchina virtuale realizzata dal SO (dal punto di vista dei processi):</p>
<ul>
<li>
<p>dispone di periferiche dedicate ai singoli processi.</p>
<p>Illude quindi i processi di avere a disposizione tutte le risorse disponibili;</p>
</li>
<li>
<p>maschera le caratteristiche fisiche delle periferiche.</p>
<p>I processi non conoscono quali risorse compongono effettivamente l’hardware poiché il SO crea un’astrazione di queste rendendo il loro accesso uniforme.</p>
<p>Quindi nel caso di un lettura o scrittura il processo che la richiede non sà effettivamente le caratteristiche fisiche dell’hardware su cui sta scrivendo o leggendo.</p>
<p>A conoscere ciò sono i driver specifici che implementano effettivamente le operazioni di lettura e scrittura specifiche per il determinato hardware in questione.</p>
</li>
<li>
<p>gestisce parzialmente i malfunzionamenti delle periferiche.</p>
</li>
</ul>
<h2 id="file-system"><a class="header" href="#file-system">File system</a></h2>
<p>Permette di trasformare un enorme contenitore di bit disordinati, memoria secondaria, in un archivio ordinato.</p>
<p>Quindi gli strati superiori vedranno un’organizzazione ordinata della memoria.</p>
<p>Al livello <strong>file system</strong>, la macchina virtuale realizzata dal SO (dal punto di vista del processo):</p>
<ul>
<li>
<p>gestisce blocchi di informazioni su memoria di massa strutturati logicamente;</p>
<p>Quindi delle sequenze di byte memorizzate in memoria di massa identifica le sequenze che rappresentano cartelle e file;</p>
</li>
<li>
<p>ne controlla gli accessi;</p>
<p>Per ogni accesso verifica se il processo richiedente ha i permessi necessari per leggere o scrivere su tale blocco di memoria.</p>
<p>Questo perché ogni file ha associato dei metadati. Tra questi metadati ci sono le informazioni riguardanti i permessi di accesso da parte dei processi;</p>
</li>
<li>
<p>ne gestisce l’organizzazione.</p>
<p>Gestisce la geometria della memoria di massa e implementa i metodi che devono essere utilizzare per accedere correttamente ai dati.</p>
</li>
</ul>
<h2 id="architettura-dei-sistemi-operativi"><a class="header" href="#architettura-dei-sistemi-operativi">Architettura dei sistemi operativi</a></h2>
<p>Il SO è un programma di notevole <strong>complessità</strong> e <strong>dimensione</strong>. Infatti tutti i <strong>layer</strong> che abbiamo visto prima, necessari per garantire la virtualizzazione dell’hardware e una sua gestione efficiente, fanno <strong>parte</strong> <strong>del</strong> <strong>SO</strong>.</p>
<p>É quindi fondamentale applicare, durante il suo progetto e la sua realizzazione, le più sofisticate <strong>tecniche proprie dell’ingegneria del software</strong>, al fine di garantire un risultato che goda di tutte le <strong>proprietà che garantiscano la qualità di un sistema software</strong>: correttezza, modularità, facilità di manutenzione, efficienza di esecuzione, etc.</p>
<p>Per questo sono stati proposti, nel tempo, <strong>vari modelli strutturali</strong> cui fare riferimento <strong>per organizzare i componenti</strong> durante le fasi di progetto, realizzazione e test del sistema.</p>
<h3 id="sistemi-operativi-monolitici"><a class="header" href="#sistemi-operativi-monolitici">sistemi operativi monolitici</a></h3>
<p>I primi sistemi operativi erano costituiti da un solo programma (<strong>sistemi monolitici</strong>) senza una particolare suddivisione dello stesso in moduli.</p>
<p>Il sistema operativo era <strong>costituito da un insieme di procedure di servizio</strong> a ciascuna delle quali corrispondeva una <strong>chiamata al sistema</strong>.</p>
<p>Normalmente le procedure erano scritte in <strong>linguaggio</strong> <strong>assembler</strong> per consentire un più efficiente accesso alle risorse hardware della macchina.</p>
<p>Questo tipo di approccio al progetto del sistema poteva essere <strong>adeguato soltanto nel caso di sistemi molto semplici</strong>, come nel caso dei primi sistemi operativi e, successivamente, come nel caso di semplici <strong>sistemi non multiprogrammati</strong>, per esempio il sistema operativo MS-DOS.</p>
<p>Col crescere della complessità tipica dei moderni sistemi multiprogrammati questo approccio ha rapidamente mostrato tutti i propri limiti.</p>
<h3 id="sistemi-operativi-modulari"><a class="header" href="#sistemi-operativi-modulari">sistemi operativi modulari</a></h3>
<p>Un valido approccio utilizzato per affrontare la complessità di un sistema è quello di fare riferimento a <strong>tecniche di modularizzazione</strong> in modo tale da suddividere il sistema in componenti (moduli), <strong>ciascuno destinato a fornire una delle funzionalità del sistema</strong>.</p>
<p>Realizzato usualmente in un <strong>linguaggio di alto livello seguendo i criteri tipici della programmazione strutturata</strong> (<strong>sistemi modulari</strong>).</p>
<p>In base ai criteri della programmazione strutturata, ogni modulo è caratterizzato da una ben precisa interfaccia, che specifica la funzionalità offerta dal modulo, e un corpo contenente l’implementazione del modulo, non visibile all’esterno.</p>
<p>In questo modo ogni modifica che veniva apportata ai moduli non influenzava il funzionamento degli altri, a meno che la modifica non era fatta sull’interfaccia offerta dal modulo.</p>
<p>Il primo esempio di strutturazione di un sistema operativo fu quello di che si ottenne modificando la struttura dei primi sistemi monolitici in modo tale da identificare i vari moduli componenti e dettagliando con cura le rispettive interfacce.</p>
<p align="center"><img src="images/interfaccia_modulo.png" width="300"></p>

<p>I vari moduli furono distinti in due categorie:</p>
<ul>
<li>le procedure di servizio offerte dal sistema ai programmi applicativi tramite chiamate di sistema;</li>
<li>le procedure di utilità, utilizzate dalle prime ma non direttamente visibili ai processi.</li>
</ul>
<p align="center"><img src="images/suddivisione_in_moduli.png" width="400"></p>

<p>Ovviamente ogni chiamata di sistema provocava un cambio di contesto da modalità utente a modalità kernel.</p>
<p>Questo tipo di struttura è anche quella adottata nel sistema Unix.</p>
<p>In questo caso fanno parte del sistema:</p>
<ul>
<li>sia le tipiche <strong>componenti di un sistema operativo</strong>, invocate tramite le chiamate di sistema, eseguite in <strong>stato</strong> <strong>privilegiato</strong> e identificate globalmente con il termine <em>kernel</em></li>
<li>sia <strong>l’insieme dei programmi di utilità del sistema</strong> costituiti dalla shell, dai compilatori, dai caricatori, dai linker e dalle librerie di sistema, eseguiti in stato non privilegiato come i normali programmi utente.</li>
</ul>
<p>Nonostante gli indubbi vantaggi indotti dall’uso di tecniche di modularità, la complessità dei sistemi operativi è andata progressivamente crescendo, richiedendo quindi ulteriori paradigmi di progetto in grado di affrontare in modo più idoneo la crescente complessità.</p>
<h3 id="sistemi-operativi-a-livelli-gerarchici-di-astrazione"><a class="header" href="#sistemi-operativi-a-livelli-gerarchici-di-astrazione">sistemi operativi a livelli gerarchici di astrazione</a></h3>
<p>Consistono in SO modulari, organizzati in una struttura gerarchica.</p>
<p>Uno degli aspetti fondamentali della tecnica dell’organizzazione gerarchica consiste nel <strong>ridurre il numero di possibili interconnessioni</strong> fra i moduli di un sistema, semplificando quindi sia la fase di progetto sia quella di verifica.</p>
<p>Ovvero si punta ad ottenere un’organizzazione in moduli che punti a diminuire le dipendenze tra questi e quindi aumentare il livello di coesione.</p>
<p>Tale tecnica che permette questo tipo di organizzazione di un sistema operativo è possibile applicarla seguendo due possibili paradigmi complementari.</p>
<ul>
<li>
<p>top-down, livelli di raffinamento successivi.</p>
<p>Consiste nello scomporre il sistema software nelle sue funzionalità principali, astraendo i dettagli implementativi. Successivamente ciascuna di queste funzionalità veniva a sua volta scomposta in altre funzionalità che la comprendessero astraendo sempre i dettagli implementativi; e così via.</p>
<p>Fino a che non si arrivi ad un livello di funzionalità elementare da cui può iniziare l’implementazione.</p>
</li>
<li>
<p>bottom-up.</p>
<p>Consiste nel partire dal basso, quindi a stretto contatto con l’hardware.</p>
<p>Implementare delle funzionalità aggiuntive che non sono disponibili in hardware e da queste funzionalità si parte ad implementarne che le utilizzino.</p>
<p>Quindi si arriva ad un livello che non è più necessario comunicare direttamente con l’hardware grazie alle funzionalità elementari che sono state implementate in principio.</p>
<p>Questo quindi permette di implementare funzionalità che astraggono sempre di più il livello hardware.</p>
</li>
</ul>
<p>Un utilizzo combinato di questi due paradigmi permette di realizzare <strong>sistemi operativi strutturati in moduli organizzati gerarchicamente in diversi livelli di astrazione</strong>, in modo tale che i <strong>moduli realizzati a un certo livello</strong> utilizzano esclusivamente le <strong>funzionalità offerte dai moduli di livello più basso</strong> e <strong>forniscano le loro funzionalità ai moduli</strong> di livello più alto.</p>
<p>Possiamo intendere questa struttura come se ogni livello definisse una nuova macchina astratta, le cui funzionalità sfruttano quelle offerte dalla macchina astratta di livello inferiore.</p>
<p align="center"><img src="images/sys_gerarchici.png" width="200"></p>

<h3 id="sistemi-operativi-a-microkernel"><a class="header" href="#sistemi-operativi-a-microkernel">sistemi operativi a microkernel</a></h3>
<p>La necessità di proteggere dall’acceso diretto l’hardware da parte dei programmi utente che avrebbero potuto causare dei danni irreparabili si è introdotto il concetto dei livelli di esecuzione:</p>
<ul>
<li>kernel mode</li>
<li>user mode</li>
</ul>
<p>Questo però ha portato il sistema ad essere più difficilmente modificabile ed estensibile.</p>
<p>Modifiche o estensioni potrebbero risultare necessarie in vari casi:</p>
<ul>
<li>si deve aggiungere un driver in seguito alla connessione di un nuovo dispositivo</li>
<li>si intende modificare alcune scelte relative alla gestione di una o più risorse al fine di rendere il sistema più adatto ai requisiti imposti dai programmi applicativi specifici che andranno in esecuzione su questo.</li>
</ul>
<p>Per dare una soluzione a questo tipo di problemi è stata proposta una soluzione nota col nome di <strong>struttura</strong> <strong>a</strong> <strong>microkernel</strong>.</p>
<p>Il microkernel implementa solo i <strong>meccanismi essenziali</strong> a discrezione del progettista.</p>
<p>Tutte le <strong>strategie per la gestione</strong> delle risorse sono implementate all’esterno del kernel, da processi di sistema che girano in user mode.</p>
<p>Quindi sono facilmente modificabili ed estensibili.</p>
<ul>
<li>Driver</li>
<li>Memory management</li>
<li>CPU scheduling</li>
</ul>
<p>Ovviamente è inevitabile che tutti questi programmi non abbiano la necessità di operare direttamente sulle risorse hardware, quindi si utilizzano comunque delle componenti del SO che girano in kernel mode per espletare alcune funzioni. → context switch</p>
<p>Questa struttura permette di aumentano l’affidabilità e la sicurezza dei sistemi perché gli eventuali guasti non si propagano nel kernel, ma rimangono in user mode.</p>
<p>I gestori delle risorse sono particolari processi di sistema, spesso indicati come <strong>server</strong> (file server, terminal server, printer server, …).</p>
<p>Quando un processo applicativo deve usare una risorsa, deve interagire con il processo server gestori di quella risorsa attraverso i meccanismi di comunicazione forniti dal microkernel.</p>
<p>La comunicazione interprocesso è la caratteristica svantaggiosa di questa struttura perché provoca una perdita delle performance.</p>
<p>Il motivo principale è dovuto al maggior numero di context switch necessari per espletare un singolo servizio ad un processo client.</p>
<p>Infatti utilizzando il comando <code>time</code> in UNIX, che misura il tempo che un processo trascorre in user-mode, in kernel-mode e l’attesa nel caso di operazioni di IO, si sono notate le perdite di performance.</p>
<h2 id="esempio-di-architetture-modulari-linux"><a class="header" href="#esempio-di-architetture-modulari-linux">Esempio di architetture modulari: linux</a></h2>
<p>Il kernel Linux è monolitico perché è un unico binario che viene caricato in memoria centrale.</p>
<p>Nel tempo è stato introdotto il meccanismo dei moduli caricabili che ha permesso quindi di estendere le funzionalità del kernel senza la necessità che questo venga ricompilato ogni volta.</p>
<p>Quindi possiamo dire che il kernel linux ha un’architettura monolitica e modulare perché implementa il meccanismo dei moduli caricabili che possono essere collegati e scollegati dal kernel a runtime.</p>
<p>I comandi per caricare o scaricare un modulo dal kernel sono:</p>
<ul>
<li><code>insmod</code></li>
<li><code>rmmod</code></li>
</ul>
<p>Il rischio che si corre con questa struttura è che i moduli che possono essere collegati al kernel girano nello stesso spazio di indirizzamento del kernel, quindi se questi hanno un bug grave possono mandare in crash l’intero sistema (kernel panic).</p>
<p>In generale, il progetto del kernel linux ha cercato di prendere i vantaggi dei due mondi: monolitico e flessibilità modulare.</p>
<h2 id="windows-acrchitecture"><a class="header" href="#windows-acrchitecture">Windows acrchitecture</a></h2>
<p>Struttura modulare per renderlo più flessibile. Questo sistema è basato su un’architettura a microkernel ibrida.</p>
<ul>
<li>Non è puramente un’architettura a microkernel, anche se la maggior parte delle funzionalità sono eseguite all’esterno del microkernel.</li>
<li>Tutti i moduli esterni sono caricati dinamicamente e quindi posso essere rimossi, aggiornati, o sostituiti senza riscrivere o ricompilare tutto il sistema.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><script src="../javascript.js"></script>
<h1 id="scheduler"><a class="header" href="#scheduler">Scheduler</a></h1>
<p>Con il termine <em>short term scheduler</em> si intende quella funzione del nucleo che ha il compito di gestire l’allocazione della CPU ai processi che si trovano nella coda dei processi pronti.</p>
<p>In generale, lo <em>sheduler</em> è quella parte del SO preposta all’assegnazione di risorse a favore dei processi richiedenti.</p>
<p>La selezione tra i processi richiedenti (coda dei relativi PCB) nella coda può avvenire mediante differenti criteri, a seconda <strong>dell’algoritmo di scheduling</strong> che implementa uno schedulatore.</p>
<p>Questo è un compito fondamentale per tutti i sistemi multiprogrammati in cui c’è la necessità di un efficiente gestione delle risorse condivise disponibili per tutti i processi attivi e che eseguono in modo concorrente.</p>
<p>Inoltre gli sheduler sono i componenti più caratterizzanti del sistema operativo, infatti da questa si possono identificare le caratteristiche e gli obiettivi per cui è stato progettato.</p>
<p>Dal punto di vista dell’esecuzione dei processi abbiamo diversi scheduler ognuno che si occupa di svolgere un particolare compito:</p>
<ul>
<li><em>long term scheduling</em> o di job</li>
<li><em>medium term scheduling</em> o di swap</li>
<li><em>short term scheduling</em> o della CPU</li>
</ul>
<h2 id="scheduling-a-lungo-termine"><a class="header" href="#scheduling-a-lungo-termine">Scheduling a lungo termine</a></h2>
<p>Con <strong>sheduling a lungo termine</strong> si intende quella funzione del sistema operativo che, in un sistema di tipo batch, sceglie tra tutti i programmi caricati in memoria di massa per essere eseguiti, quelli da trasferire in memoria centrale e da inserire nella coda dei processi pronti.</p>
<p>Quindi controlla il <strong>grado di multiprogrammazione</strong> del sistema.</p>
<p>Le sue scelte, in genere, vengono fatte in modo da equilibrare la presenza in memoria centrale di processi caratterizzati da prevalenza di operazioni di elaborazione (CPU bound) e di processi caratterizzati da prevalenza di operazioni di ingresso e uscita (I/O bound).</p>
<p>In modo da distribuire il carico in modo ottimale su tutte le risorse disponibili.</p>
<p>Troppi processi I/O bound → la coda dei processi pronti è sempre quasi vuota</p>
<p>Troppi processi CPU bound → i dispositivi I/O sarebbero poco utilizzati</p>
<p>I possibili criteri su cui si può basare la scelta dello scheduler a lungo termine sono:</p>
<ul>
<li>FIFO</li>
<li>Priorità</li>
<li>Tempo di esecuzione stimato</li>
<li>Requisiti di I/O → processi I/O bound</li>
<li>Tempo presunto di CPU → processi CPU-bound</li>
</ul>
<h2 id="scheduling-a-medio-termine"><a class="header" href="#scheduling-a-medio-termine">Scheduling a medio termine</a></h2>
<p>Lo <strong>scheduling a medio termine</strong> rappresenta invece quella funzione del sistema operativo che ha il compito di trasferire temporaneamente processi dalla memoria centrale alla memoria di massa (<em>swap-out</em>) e viceversa (<em>swap-in</em>).</p>
<p>Questa funzione è necessaria, in caso di RAM prossima alla saturazione, di liberare parte della memoria centrale necessaria ad altri processi già presenti o per rendere possibile il caricamento di nuovi processi.</p>
<p>Il suo obiettivo è quello di <strong>migliorare</strong> <strong>l’efficienza</strong> nell’utilizzo della risorsa <strong>memoria</strong>.</p>
<p>Se questa gestione dei trasferimenti di processi verso e da la memoria di massa non è fatta in modo efficiente si verificherebbero molte operazioni di I/O per spostare i processi tra le memorie.</p>
<ul>
<li>ad esempio nel caso in cui due processi si trovino a collaborare e quindi l’esecuzione dell’uno dipende dall’esecuzione dell’altro;</li>
<li>supponiamo di avere implementato due processi che operano su una memoria condivisa secondo il paradigma produttori consumatori</li>
<li>se il produttore venisse sempre swappato in memoria di massa, allora questo poi dovrà esser reintrodotto in memoria centrale per permette al consumatore di consumare la risorsa.</li>
</ul>
<hr>
<p>Entrambe le funzioni di long term scheduling e medium term scheduling vengono eseguite dal sistema operativo con una frequenza nettamente inferiore a quella della short term scheduling.</p>
<p>Quindi possono risultare meno costose in termini di tempo di esecuzione e quindi non inficiare molto sulle performance del sistema.</p>
<p>Invece la funzione di short term sheduling è eseguita molto frequentemente, ad ogni context switch, in modo da rendere l’esecuzione di più processi fluida, dando l’impressione che siano eseguiti in parallelo all’utente.</p>
<p>Quindi deve essere una funzione su cui porre l’attenzione per la ottimizzazione, poiché inficia molto sulle performance generali del sistema.</p>
<p>Possiamo dire che tra gli scheduler è quello più caratterizzante del SO.</p>
<p align="center"><img src="images/scheduler_lms.png" width="200"></p>

<h2 id="processi-cpu-bound-e-io-bound"><a class="header" href="#processi-cpu-bound-e-io-bound">Processi CPU bound e I/O bound</a></h2>
<ul>
<li>Processi <strong>CPU-bound</strong>
<ul>
<li>poche chiamate di sistema</li>
<li>tendono ad occupare la CPU per lunghi periodi (se il SO non li interrompe)</li>
<li>tipico delle applicazioni batch, calcolo numerico</li>
</ul>
</li>
</ul>
<p align="center"><img src="images/cpu-bound.png" width="400"></p>

<ul>
<li>Processi <strong>I/O-bound</strong>
<ul>
<li>fanno frequenti chiamate di sistema</li>
<li>usano brevemente la CPU, per poi mettersi subito in attesa di I/O</li>
<li>tipico dei programmi <strong>interattivi</strong> (es. browser, editor di testo, …)</li>
</ul>
</li>
</ul>
<p align="center"><img src="images/IO-bound.png" width="400"></p>

<h2 id="scheduler-a-breve-termine"><a class="header" href="#scheduler-a-breve-termine">Scheduler a breve termine</a></h2>
<p>Lo scheduler a breve termine, conosciuto anche con il nome di <strong>dispatcher</strong>, è lo scheduler che viene attvato più frequentemente nel sistema.</p>
<p>Ha il compito di <strong>scegliere a quale tra i processi pronti</strong> assegnare la CPU.</p>
<p>Lo scheduler a breve termine viene invocato all’occorrenza di un evento che comporta la sospensione del processo in esecuzione.</p>
<p>Tali eventi sono per esempio:</p>
<ul>
<li>interruzioni del Clock (timer)</li>
<li>interruzioni di I/O</li>
<li>system call</li>
<li>segnali (ad esempio semafori su cui erano sospesi per la cooperazione)</li>
</ul>
<p>L’obiettivo dell’algoritmo del <strong>Dispatcher</strong> è quello di allocare il processore in maniera tale da ottimizzare uno o più aspetti del comportamento del sistema.</p>
<p>I criteri più utilizzati sono:</p>
<ul>
<li>
<p>User-oriented</p>
<p>Si riferiscono ai comportamenti del sistema così come <strong>percepiti dall’utente o da un processo</strong>.</p>
<p>→ Ad esempio il tempo di risposta.</p>
</li>
<li>
<p>System-oriented</p>
<p>L’obiettivo è quello di <strong>utilizzare in modo efficiente il processore</strong>.</p>
<p>Quindi massimizzare l’utilizzo della risorsa processore.</p>
<p>→ Ad esempio migliorare il throughput di esecuzione.</p>
</li>
</ul>
<p>Ovviamente il comportamento del sistema comprende diverse caratteristiche possibili che possono essere ottimizzate.</p>
<p>Ma molte di queste fanno in conflitto.</p>
<p>Infatti enfatizzando le caratteristiche del sistema operativo che portano a massimizzare il thoughput del processore si attenuano le caratteristiche che si riferiscono alla percezione dell’utente o dei processi utente, come ad esempio il tempo di risposta.</p>
<p>Quindi non esiste un algoritmo universale a cui aspirare per ottenere il meglio in tutti i campo possibili. Ma esistono i migliori algoritmi rispetto agli obiettivi di progetto scelti per la realizzazione del SO.</p>
<h3 id="parametri-user-oriented"><a class="header" href="#parametri-user-oriented">Parametri User-oriented</a></h3>
<ul>
<li>
<p><strong>Tempo di turnaround</strong>: <strong>intervallo</strong> di <strong>tempo</strong> che trascorre dall’istante in cui un processo è ammesso nel sistema all’istante della sua terminazione.</p>
<p>Tiene conto del <strong>tempo effettivo di esecuzione</strong> e <strong>del tempo speso in attesa delle risorse</strong> (CPU inclusa).</p>
</li>
<li>
<p><strong>Tempo di risposta</strong>: indica il tempo che trascorre dall’istante della ammissione nel sistema (quindi quando entra nella coda dei processi pronti per la prima volta) all’istante in cui fornisce la prima risposta.</p>
</li>
<li>
<p><strong>Deadlines</strong>: nel caso in cui si possa specificare per ogni processo il termine di completamento (deadline), l’algoritmo dello scheduler a breve termine deve seguire una metrica che porta a <strong>massimizzare la percentuale scadenze raggiunte</strong>.</p>
</li>
<li>
<p><strong>Tempo di servizio</strong>: è il tempo di esecuzione “puro” del processo, cioè quanto tempo serve al processo per terminare se avesse la CPU tutta per sé, senza interruzioni o attese.</p>
</li>
<li>
<p><strong>Slowdown</strong> è il rapporto tra il <em>tempo di turnaround</em> e il <em>tempo di servizio</em>.</p>
<p>Misura quanto un processo è stato rallentato dal sistema rispetto al tempo che avrebbe impiegato se fosse stato eseguito da solo, senza attese.</p>
<p>Un valore pari ad <code>1</code> indica che il processo ha avuto esecuzione immediata (nessuna attesa).</p>
</li>
</ul>
<h3 id="parametri-system-oriented"><a class="header" href="#parametri-system-oriented">Parametri System-oriented</a></h3>
<ul>
<li>
<p><strong>Throughput</strong>: misura la <strong>produttività</strong> di un sistema in termini di <strong>numero di processi terminati per unità di tempo</strong>.</p>
<p>Questo parametro <strong>dipende</strong> fortemente dalla <strong>lunghezza media di un processo</strong> ma è anche <strong>influenzato</strong> dalla particolare <strong>politica adottata per la schedulazione</strong>.</p>
</li>
<li>
<p><strong>Utilizzo della CPU</strong>: rappresenta la percentuale di tempo per cui il processore risulta occupato.</p>
<p>L’obiettivo è di massimizzare la percentuale d’uso della CPU nell’unità di tempo.</p>
</li>
<li>
<p><strong>Fairness</strong>: misura quanto i processi attivi nel sistema, che quindi sono pronti ad eseguire o sono bloccati in attesa di un evento asincroni, sono <strong>trattati equamente in termini di schedulazione</strong>.</p>
<p>Questo parametro esclude qualsiasi concetto di priorità dei processi all’interno del sistema.</p>
<p>→ evita che ci siano situazioni di starvation per un processo.</p>
</li>
</ul>
<h2 id="esiste-un-algoritmo-perfetto"><a class="header" href="#esiste-un-algoritmo-perfetto">Esiste un algoritmo perfetto?</a></h2>
<ul>
<li>Naturalmente NO!</li>
</ul>
<p>Ovviamente i parametri descritti che riguardano l’User-oriented e il System-oriented sono interdipendenti tra loro ma alcuni sono nettamente in contrasto.</p>
<p>Ad esempio ottenere una politica <em>fair</em> non mi garantisce una massimizzazione dell’<em>utilizzo della CPU</em> o il <em>deadlines</em>.</p>
<p>Mentre ottenere una politica che va verso la minimizzazione del <em>turnaround time</em> porta anche un miglioramento del <em>tempo di risposta</em>.</p>
<blockquote>
<p>Il progetto e l’implementazione di una politica di scheduling implica sempre un compromesso tra vari requisiti constrastanti.</p>
<p>La scelta dovrà essere fatta tenendo conto “per cosa dovrà essere utilizzato il sistema”.</p>
</blockquote>
<h2 id="utilizzo-delle-priorità"><a class="header" href="#utilizzo-delle-priorità">Utilizzo delle priorità</a></h2>
<p>Lo scheduler può scegliere i processi in base alla loro priorità.</p>
<p>Le priorità assegnate ai processi possono essere:</p>
<ul>
<li><strong>Statiche</strong>, se non si modificano durante il periodo di vita del processo nel sistema.</li>
<li><strong>Dinamiche</strong>, se durante il loro ciclo di vita i processi possono modificare la loro priorità in base ad alcuni parametri come: tempo di CPU o tempo di I/O.</li>
</ul>
<p>I processi sono tipicamente raggruppati in <strong>classi di priorità</strong></p>
<ul>
<li>L’algoritmo di scheduling dovrà scegliere un processo pronto che appartiene alla classe di priorità più alta.</li>
</ul>
<h2 id="starvation"><a class="header" href="#starvation">Starvation</a></h2>
<p>L’utilizzo di un algoritmo di scheduling a priorità può indurre situazioni di <strong>attesa indefinita</strong> di processi a priorità più bassa (<strong>starvation</strong>).</p>
<p>Per far fronte a queste situazioni si utilizzano schemi di priorità dinamiche.</p>
<p>Come ad esempio, utilizzare un aumento graduale della priorità dei processi che si trovano in attesa nel sistema da lungo tempo → <strong>Aging</strong>.</p>
<hr>
<p>EPISODIO esemplificativo dei problemi che può causare la starvation:</p>
<p>L’IBM 7094, un computer progettato per applicazioni scientifiche e tecnologia su larga scala, ha avuto il più eclatante problema di starvation.</p>
<p>Questo computer è stato utilizzato dalla NASA e per operazioni militari ed è stato introdotto nel 1962 e ha terminato il suo servizio nel 1973.</p>
<p>Quando è terminato il servizio gli utenti trovarono un processo a bassa priorità che fu ammesso nel sistema nel 1976 non è mai terminato perché nella coda dei processi pronti si presentavano ogni volta processi a priorità maggiore.</p>
<p>In questi casi la soluzione è quella di implementare la tecnica di Aging che consiste nel aumentare gradualmente la priorità di un processo in attesa sulla coda dei processi pronti rispetto ad alcuni parametri, come il tempo di attesa per ottenere la risorsa CPU.</p>
<h2 id="classificazione-relativa-al-momento-in-cui-interviene-lo-scheduling"><a class="header" href="#classificazione-relativa-al-momento-in-cui-interviene-lo-scheduling">Classificazione relativa al momento in cui interviene lo scheduling</a></h2>
<p>Una prima classificazione fra gli algoritmi di scheduling è relativva alla scelta di quali siano gli eventi in seguito ai quali lo scheduler deve intervenire:</p>
<ul>
<li>
<p>Si indicano come algoritmi di scheduling senza diritto di <em>revoca</em> (<em>non preemptive</em>) tutti quelli che prevedono l’intervento dello scheduler esclusivamente quando il processi in esecuzione libera spontaneamente la CPU, o perché termina la propria esecuzione o perché si sospende in attesa del verificarsi di un dato evento asincrono.</p>
</li>
<li>
<p>Invece, vengono indicati come algoritmi con il diritto di <em>revoca</em> (<em>preemptive</em>) quelli che prevedono l’intervento dello scheduler anche per decidere di revocare la CPU al processo in esecuzione al fine di allocarla ad un altro processo in attesa sulla coda dei processi pronti.</p>
<p>Per esempio a causa dell’arrivo di un segnale di interruzione che indica lo scadere del quanto di tempo assegnato al processo, oppure perché entra in coda dei processi pronti un processo ritenuto “urgente”.</p>
<p>In entrambi i casi il processo in esecuzione viene forzato a rilasciare la risorsa CPU preventivamente e inserito nella coda dei processi pronti.</p>
</li>
</ul>
<p>Gli algoritmi <em>non preeptive</em> sono sicuramente quelli più semplici e riducono il numero delle volte che lo scheduler deve intervenire e quindi il <strong>numero di cambi di contesto</strong> fra processi. → Richiedono un minor <em>overhead</em> di sistema.</p>
<p>Allo stesso tempo sono anche quelli che non offrono una flessibilità in termini di strategie di scheduling.</p>
<div style="break-before: page; page-break-before: always;"></div><script src="../javascript.js"></script>
<h1 id="deadlock"><a class="header" href="#deadlock">Deadlock</a></h1>
<p>Deadlock è un fenomeno che può presentarsi nelle <strong>applicazioni concorrenti</strong> che porta a un blocco permanente di processi in <strong>competizione per risorse condivise</strong>.</p>
<p>→ può portare a crash, situazioni di stallo, etc. (da evitare completamente)</p>
<p>Nei sistemi operativi <strong>general-porpose</strong>, si ammette l’esistenza di deadlock → non si implementano tecniche per evitare il problema ma si rileva nel momento in cui si presenta e si cerca di risolverlo.</p>
<h2 id="deadlock-definizione-e-generalità"><a class="header" href="#deadlock-definizione-e-generalità">Deadlock: definizione e generalità</a></h2>
<p>Indica una situazione di <strong>blocco permanente</strong> di un gruppo di processi in competizione per le risorse di sistema (che sono limitate → motivo principale per cui si deve gestire la competizione).</p>
<p>Deadlock è un problema complesso e di rilievo, che può provocare gravi malfunzionamenti.</p>
<p>A seconda dello scopo per cui è progettato, un sistema operativo adotta una <strong>gestione</strong> diversa per controllare il deadlock.</p>
<p>Ad esempio, per i sistemi <strong>real-time</strong> evitare il deadlock è fondamentale, quindi avranno una gestione più rigida che tende a prevenire tali fenomeni a differenza di altri tipi di sistemi operativi, come general-porpose, che potranno tendere a non rilevarli e risolverli a posteriori.</p>
<hr>
<p>Esempio: attraversamento di un incrocio</p>
<p align="center"><img src="images/incrocio_deadlock.png" width="450"></p>

<p>Sono presenti diversi quadranti identificati dalle lettere <code>a</code>, <code>b</code>, <code>c</code> e <code>d</code>; che possono rappresentare le risorse critiche.</p>
<ul>
<li>Ogni auto ha bisogno di attraversare due quadranti;</li>
<li>Ogni auto rappresenta un processo di un sistema operativo.</li>
</ul>
<p>Ogni si inserisce nel rispettivo primo quadrante, ma per completare la curva deve ottenere l’accesso al quadrante alla loro destra (o sinistra) occupato da un’altra auto, e per quest’ultima vale lo stesso ragionamento.</p>
<p>Facendo lo stesso ragionamento si crea un situazione di stallo (se nessun’auto indietreggia).</p>
<hr>
<p>Esempio: copia di un file</p>
<ul>
<li>un sistema ha 2 dischi esterni</li>
<li><code>P1</code> e <code>P2</code> copiano un grosso file da un disco all’altro;</li>
<li>si suppone sia necessaria la <strong>mutua esclusione</strong>.</li>
</ul>
<p>Quindi ciascun processo acquisisce uno dei due dischi per leggere e successivamente richiedono l’accesso all’altro.</p>
<p>Ma l’altro disco si ritrova già acquisito. Quindi i due processi attendono a vicenda che l’altro rilasci la risorse.</p>
<p align="center"><img src="images/esempio_dischi.png" width="350"></p>

<p>→ si crea la cosiddetta <strong>attesa circolare</strong> che è la manifestazione del deadlock.</p>
<hr>
<h3 id="il-problema-del-deadlock"><a class="header" href="#il-problema-del-deadlock">Il problema del deadlock</a></h3>
<p>Una condizione <strong>necessaria</strong> affinché nelle <strong>applicazioni concorrenti</strong> si verifichi un deadlock è che siano presenti almeno due semafori <strong>mutex</strong>, ovvero entrambi inizializzati ad 1.</p>
<p>Quindi quando è presente la <strong>mutua esclusione</strong>.</p>
<div style="display:flex; gap:20px;">
  <!-- Colonna P1 -->
<div style="border:2px solid #b7c0e3; background:#eef1ff; padding:15px; width:45%; border-radius:6px; color:#2b2b2b;">
  <b>P₁</b><br><br>
  wait (<span style="color:red;">mutex1</span>)<br>
  &lt;inizio uso disco 1&gt;<br>
  …<br><br>
  
<div style="border:2px dashed red; padding:6px; border-radius:4px; color:#2b2b2b;">
    wait (<span style="color:green;">mutex2</span>)
  </div>

<p>&lt;inizio uso disco 2&gt;<br>
…<br><br>
signal (<span style="color:green;">mutex2</span>)<br>
…<br>
signal (<span style="color:red;">mutex1</span>)<br></p>
</div>

  <!-- Colonna P2 -->
<div style="border:2px solid #d0d0d0; background:#f5f5f5; padding:15px; width:45%; border-radius:6px; color:#2b2b2b;">
  <b>P₂</b><br><br>
  wait (<span style="color:green;">mutex2</span>)<br>
  &lt;inizio uso disco 2&gt;<br>
  …<br><br>
  
<div style="border:2px dashed red; padding:6px; border-radius:4px; color:#2b2b2b;">
    wait (<span style="color:red;">mutex1</span>)
  </div>

<p>&lt;inizio uso disco 1&gt;<br>
…<br><br>
signal (<span style="color:red;">mutex1</span>)<br>
…<br>
signal (<span style="color:green;">mutex2</span>)<br></p>
</div>

</div>

<p>I due processi potrebbero sospendersi entrambi su le <code>wait()</code> evidenziate.</p>
<p>Questo è un classico esempio di attesa circolare che si presenta se avviene la seguente sequenza di azioni:</p>
<ul>
<li><code>P1</code> esegue <code>wait(mutex1)</code> e acquisisce la prima risorsa critica;</li>
<li><code>P2</code> esegue <code>wait(mutex2)</code> e acquisisce la seconda risorsa critica;</li>
<li><code>P1</code> ha bisogno della seconda risorsa critica, quindi esegue <code>wait(mutex2)</code> e si blocca;</li>
<li><code>P2</code> ha bisogno della prima risorse critica, quindi esegue <code>wait(mutex1)</code> e si blocca.</li>
</ul>
<p>Nel caso in cui l’esecuzione dei due processi segue questa sequenza, i due processi rimangono bloccati</p>
<p>Questa situazione però <strong>non</strong> <strong>è</strong> <strong>detto</strong> che accada a ogni esecuzione dell’applicazione concorrente.</p>
<p>→ <strong>non</strong> è un fenomeno <strong>deterministico</strong>, ovvero non significa che questo si manifesti ogni volta che si hanno le condizioni adatte.</p>
<p>In alcuni casi il deadlock dipende da come i processi si alternano sulla CPU.</p>
<p>Per questo motivo il deadlock può manifestarsi <strong>saltuariamente</strong>, in base alla <strong>velocità relativa di esecuzione dei processi</strong>.</p>
<blockquote>
<p>La velocità relativa di esecuzione dei processi è un modo per descrivere come i processi avanzano nel tempo l’uno rispetto l’altro, questo avanzamento non è deterministico perché durante l’esecuzione possono:</p>
<ul>
<li>essere interrotti dal kernel (preemption),</li>
<li>essere sospesi in attesa di un operazione di I/O (la cui durata non è sempre la stessa),</li>
<li>ricevere più o meno tempo di CPU in base alla politica di sheduling adottata,</li>
<li>essere ritardati da cache miss.</li>
</ul>
</blockquote>
<p>Come si potrebbe risolvere questa situazione?</p>
<p>Un terzo dovrebbe gestire questa concorrenza, andando ad esempio a killare un processo in modo che questo liberi la risorsa detenuta a favore dell’altro.</p>
<div align="center">
<h2 id="deadlock--starvation"><a class="header" href="#deadlock--starvation"><strong>Deadlock ≠ Starvation</strong></a></h2>
<table>
<tr>
<td align="center" style="border: none">
<p><strong>attesa <span style="color:red">infinita</span></strong></p>
</td>
<td align="center" style="border: none">
<p><strong>attesa <span style="color:red">indefinita</span></strong></p>
</td>
</tr>

</table>

</div>

<p>Deadlock e starvation sono due concetti totalmente diversi che possono essere confusi.</p>
<ul>
<li>
<p>Con starvation identifichiamo una situazione di attesa <strong>indefinita</strong>. Tale fenomeno è molto legato al concetto di priorità.</p>
</li>
<li>
<p>Con deadlock identifichiamo una situazione di attesa <strong>infinita</strong>, in nessun modo i processi possono uscire da questa situazione, al contrario della starvation. Tale fenomeno è molto legato al concetto di mutua esclusione.</p>
</li>
</ul>
<h2 id="grafo-di-assegnazione-delle-risorse"><a class="header" href="#grafo-di-assegnazione-delle-risorse">Grafo di assegnazione delle risorse</a></h2>
<p>Il grafo si assegnazione delle risorse serve a modellare in modo formale lo stato delle risorse e dei processi di un sistema, per poter <strong>capire se esiste il rischio di deadlock</strong>.</p>
<p>Tramite questa formalizzazione possiamo implementare algoritmi in grado di rilevare una possibile manifestazione di deadlock tra i processi in esecuzione.</p>
<p>Un grafo è un insieme di vertici (o nodi) <em>V</em> e un insieme di archi <em>E</em>.</p>
<ul>
<li>
<p>V è partizionato in <strong>due tipi</strong>:</p>
<ul>
<li><em>P</em> = {P1, P2, …, Pn} è l’insieme costituito da tutti i <strong>processi</strong> nel sistema.</li>
<li><em>R</em> = {R1, R2, …, Rn} è l’insieme costituito da tutti i tipi di <strong>risorse</strong> nel sistema.</li>
</ul>
</li>
<li>
<p><strong>Arco di richiesta</strong> (arco orientato) Pi → Rj, Pi chiede l’accesso a Rj.</p>
</li>
<li>
<p><strong>Arco di assegnazione</strong> (arco orientato) Rj → Pi, Rj è assegnata al processo Pi.</p>
</li>
</ul>
<p>Ogni risorsa può avere più istanze.</p>
<p align="center"><img src="images/def_grafo.png" width="300"></p>

<p>Una condizione <strong>sufficiente</strong> per la possibile (perché dipende sempre dalla velocità relativa di esecuzione) manifestazione di un deadlock è un <strong>ciclo</strong> nel grafo di assegnazione.</p>
<p align="center"><img src="images/grafo_deadlock.png" width="300"></p>

<p>In questo caso <code>P1</code> richiede <code>Ra</code> la cui unica istanza è detenuta da <code>P2</code> che richiede a sua volta <code>Rb</code> la cui unica istanza è detenuta da <code>P1</code>.</p>
<p>Nel momento in cui è presente un ciclo del genere possiamo essere <strong>sicuri</strong> che tra questi processi è <strong>possibile</strong> che avvenga una situazione di deadlock.</p>
<p>Invece possiamo considerare che <strong>si verifica</strong> il deadlock se i processi partono da una condizione iniziale in cui hanno già in possesso le rispettive risorse e facciano una richiesta per l’altra, quando nessuno dei due processi ha terminato.</p>
<p>Ovviamente nel caso in cui le risorse avessero più istanze non ci sarebbe un problema, perché i due processi accederebbero a istanze diverse e quindi non si violerebbe la <strong>mutua esclusione</strong>.</p>
<p align="center"><img src="images/grafo_nodeadolock.png" width="300"></p>

<p>→ Questo <strong>non</strong> significa che avere più istanze <strong>risolva</strong> il problema, perché basta che si aggiungano altri processi al grafo con una particolare configurazione che la situazione di deadlock potrebbe accadere.</p>
<p>OSSERVAZIONI:</p>
<ul>
<li>
<p>Un ciclo è una condizione sufficiente per la possibile condizione di deadlock.</p>
<p>→ Se il grafo <strong>non contiene cicli</strong> ⟹ non si verificano situazioni di stallo</p>
</li>
<li>
<p>Se il grafo <strong>contiene un ciclo</strong> ⟹ si potrebbe verificare una situazione di stallo, la cui possibilità diminuisce con il numero di istanze per ogni risorsa.</p>
<p>Quindi la possibilità che ci sia un deadlock esiste ma non è detto che si verifica, perché tutto dipende anche dalla velocità relativa di esecuzione di ogni processo.</p>
</li>
</ul>
<p>Un caso che possiamo considerare UTOPICO è quando ogni risorsa ha tante istanze quanti siano i processi che potenzialmente possano richiederla → impossibile proprio perché non sappiamo il numero di processi che potenzialmente è troppo elevato e le risorse sono limitate.</p>
<p>Linux cosa fa? Quando rileva un deadlock tenta di <strong>eliminare</strong> (a posteriori) questa condizione andando a terminare uno dei processi scatenanti, la cui scelta dipende da delle metriche.</p>
<p>Quindi accetta che questa situazione può verificarsi e nel momento in cui è tale risolve il problema mediante una sua politica di gestione.</p>
<h2 id="metodi-per-la-gestione-dei-deadlock"><a class="header" href="#metodi-per-la-gestione-dei-deadlock">Metodi per la gestione dei deadlock</a></h2>
<p>Esistono diversi approcci per gestire la situazione di deadlock che consistono principalmente in prevenirli (a priori) o rilevarli (a posteriori).</p>
<ol>
<li>
<p>Prevenzione dei deadlock (<strong>PREVENTION</strong>):</p>
<p>rendere <strong>impossibile</strong> il verificarsi delle <strong>condizioni di deadlock</strong>, ma al costo di un basso utilizzo delle risorse.</p>
<p>Questo approccio tenta di annullare le condizioni che possono causare un deadlock → evitano che si creino dei cicli nel grafo di assegnazione delle risorse.</p>
<p>Ma nel fare questo <strong>limitano l’utilizzo delle risorse non sfruttandole a pieno</strong>, quindi rallentando il sistema.</p>
</li>
<li>
<p>Evitare i deadlock (<strong>AVOIDANCE</strong>):</p>
<p>le condizioni per il deadlock sono consentite, quindi si ammette l’esistenza delle condizioni tali per cui esso può avvenire, me il sistema <strong>evita di entrare</strong> in uno stato di deadlock.</p>
<p>Evita la condizione <strong>analizzando ogni richiesta</strong> di risorse prima di concederla, e <strong>accettandola solo</strong> se non porta il sistema in uno “<strong>stato non sicuro</strong>”.</p>
</li>
<li>
<p>Rilevazione del deadlock (<strong>DETECTION</strong>):</p>
<p>Si permette al sistema di entrare in uno stato di deadlock, per poi risolvere il problema (<strong>ripristino il sistema</strong>).</p>
<p>Quindi si ammette che ci possa esser la condizione di deadlock, non si fa nulla per evitarla, ma nel momento in cui questa si verifica il sistema tenta di tornare in uno stato sicuro.</p>
<p>Ovvero si gestisce il deadlock solo dopo che questo si verifica.</p>
</li>
</ol>
<p>La maggioranza dei sistemi operativi general-porpose, inclusi UNIX e Windows, <strong>non dispone di una soluzione generale ed efficiente</strong> al problema del deadlock.</p>
<p>Poiché tutte le politiche di gestione elencate hanno grandi problemi per cui non possono essere adottati.</p>
<p>NOTA: se creo due processi e faccio in modo che questi vadino in deadlock, il sistema operativo non fa nulla. Sarà un problema demandato al programmatore offrire una soluzione alla specifica situazione.</p>
<h2 id="condizioni-per-il-deadlock"><a class="header" href="#condizioni-per-il-deadlock">Condizioni per il deadlock</a></h2>
<p>Le condizioni <strong>necessarie</strong> sono:</p>
<ul>
<li>
<p><strong>Mutua esclusione</strong> → un processo per alla volta può usare la risorsa.</p>
</li>
<li>
<p><strong>Impossibilità di prelazione</strong> → una risorsa può esser rilasciata <strong>solo volontariamente</strong> dal processo che la possiede, al termine della sua esecuzione.</p>
<p>Quindi non esistono casi in cui a un processo venga prelazionata una risorsa a favore di un altro che la richiede.</p>
</li>
<li>
<p><strong>Possesso e attesa</strong> → un processo che possiede almeno una risorsa, <strong>attende di acquisire ulteriori risorse</strong> già possedute da altri processi.</p>
</li>
</ul>
<p>Invece le condizioni <strong>necessarie e sufficienti</strong> sono (tutte quelle necessarie + attesa circolare):</p>
<ul>
<li><strong>Mutua esclusione</strong></li>
<li><strong>Impossibilità di prelazione</strong></li>
<li><strong>Possesso e attesa</strong></li>
<li><strong>Attesa circolare</strong> → che abbiamo visto essere una <strong>condizione necessaria e sufficiente</strong>.</li>
</ul>
<p>Affinché ci sia attesa circolare devono necessariamente esser verificate tutte le condizioni necessarie. Quindi possiamo dire che se è presente un’attesa circolare allora automaticamente è presente una condizione di deadlock.</p>
<p>(Attesa circolare è una conseguenza di un ciclo nel grafo di assegnazione, ma non è detto che si verifichi)</p>
<p>Attesa circolare è la condizione che si verifica nel momento in cui</p>
<ul>
<li>
<p>esiste un insieme {P0, P1, P2, …, Pn} di processi in attesa, tali che:</p>
<ul>
<li>P0 è in attesa per una risorsa che è posseduta da P1</li>
<li>P1 è in attesa per una risorsa che è posseduta da P2</li>
<li>…</li>
<li>Pn-1 è in attesa per una risorsa che è posseduta da Pn</li>
<li>Pn è in attesa per una risorsa che è posseduta da P0</li>
</ul>
<p>Ovvero quando nel grafo di assegnazione si crea un ciclo di attesa perché non ci sono abbastanza istanze di risorse disponibili per cui, almeno uno, di questi processi non ha bisogno di attendere.</p>
</li>
</ul>
<p align="center"><img src="images/attesa_circolare.png" width="600"></p>

<h2 id="deadlock-prevention"><a class="header" href="#deadlock-prevention">Deadlock PREVENTION</a></h2>
<p>Nella deadlock <strong>prevention</strong>, si evita il deadlock <strong>invalidando</strong> una delle quattro condizioni necessarie e sufficienti.</p>
<p>Svantaggi nell’utilizzo di questo tipo di gestione del deadlock:</p>
<ol>
<li>mancato uso di risorse che sono disponibili;</li>
<li>esecuzione rallentata dei processi. → la politica di gestione costringe a processi ad attendere anche quando non è necessario</li>
<li>non è possibile alcun tipo di cooperazione tra processi</li>
</ol>
<h3 id="mutua-esclusione"><a class="header" href="#mutua-esclusione">Mutua esclusione</a></h3>
<p>La mutua esclusione è imposta dalle caratteristiche della risorsa e spesso non è rimovibile a meno che non si serializzi l’esecuzione dei processi, quindi non si necessita di un mutex.</p>
<p>In questo caso però peggiorano molto le performance perché non si sfrutta più la concorrenza tra i processi.</p>
<ul>
<li>
<p>Può esse rilassata in alcuni casi di risorse condivisibili</p>
<p>come, ad esempio, le risorse read-only.</p>
</li>
<li>
<p>Comporta costi maggiori → il sistema deve garantire che una risorsa critica (che potrebbe generare inconsistenze) non sia accessibile da più processi che ne fanno richiesta.</p>
<p>Quindi che la risorsa è posseduta da un solo processo per volta.</p>
</li>
</ul>
<h3 id="possesso-e-attesa"><a class="header" href="#possesso-e-attesa">Possesso e attesa</a></h3>
<p>Eliminando questa condizione si forza un processo a <strong>richiedere una risorsa solo quando non ne possiede altre</strong> (es. all’avvio richiede tutte le risorse necessarie alla sue esecuzione).</p>
<p>In questo caso si deve implementare una sorta di dichiarazione per ogni processo delle risorse che utilizza.</p>
<p>Tale dichiarazione deve contenere tutte le risorse necessarie che verranno bloccate per tutta l’esecuzione del processo. Quindi si può capire che è molto inefficiente come soluzione perché le risorse vengono bloccate per tutta l’esecuzione anche se il processo le utilizza in una piccola parte.</p>
<p>→ Approccio soggetto a <strong>starvation</strong>, perché potrebbe esistere un processo che è sempre in esecuzione e utilizza una risorsa che non potrà mai essere utilizzata da altri processi.</p>
<p align="center"><img src="images/rimozione_possesso_e_attesa.png" width="600"></p>

<ul>
<li>In questo caso se P1 non termina mai → P2 non potrà mai terminare la propria esecuzione.</li>
</ul>
<h3 id="impossibilità-di-prelazione"><a class="header" href="#impossibilità-di-prelazione">Impossibilità di prelazione</a></h3>
<p>Rilassando il vincolo di impossibilità di prelazione se un processo già possiede alcune risorse, e ne richiede un’altra che non gli può esser allocata immediatamente, allora <strong>rilascia tutte le risorse possedute</strong>.</p>
<p>Quindi non si mette in attesa per la singola risorsa che richiede, mantenendo il possesso di quelle già allocate, ma libera tutte le risorse e si mette in attesa.</p>
<p>Tale processo quindi non si metterà in attesa per la sola risorsa in più richiesta ma anche per tutte le altre che possedeva e che ha rilasciato.</p>
<p>→ il processo verrà eseguito nuovamente solo quando può riottenere il possesso sia delle <strong>vecchie che delle nuove risorse</strong>.</p>
<!-- @todo inserisci un immagine o una gif esemplificativa -->
<h3 id="attesa-circolare"><a class="header" href="#attesa-circolare">Attesa circolare</a></h3>
<p>Si stabilisce a priori un <strong>ordinamento totale</strong> tra tutte le risorse.</p>
<p>E si richiede che ogni processo richieda le risorse seguendo l’ordine prestabilito.</p>
<p>Quindi se un processo ha bisogno di utilizzare un certo numero di risorse deve richiedere l’accesso a queste nell’ordine prestabilito nonostante tale ordine non sia quello delle operazioni che effettua su queste.</p>
<p>Nell’esempio successivo P2 chiede l’accesso prima a “disco 1” poi a “disco 2” nonostante operi inizialmente solo su “disco 2”.</p>
<p>→ provoca una perdita delle performance perché un processo potrebbe possedere una risorsa per un tempo che è molto superiore rispetto al tempo effettivo nel quale opera su tale risorsa.</p>
<p>ESEMPIO:</p>
<p>Ordine imposto:</p>
<ol>
<li>disco 1</li>
<li>disco 2</li>
</ol>
<div style="display:flex; gap:20px;">
  <!-- Colonna P1 -->
<div style="border:2px solid #b7c0e3; background:#eef1ff; padding:15px; width:45%; border-radius:6px; color:#2b2b2b;">
  <b>P₁</b><br><br>
  …<br><br>
  
<div style="border:2px dashed red; padding:6px; border-radius:4px; color:#2b2b2b;">
  wait (<span style="color:red;">mutex1</span>)<br>
  &lt;inizio uso disco 1&gt;
  </div>

  …<br><br>
  wait (<span style="color:green;">mutex2</span>)
<p>&lt;inizio uso disco 2&gt;<br>
…</p>
</div>

  <!-- Colonna P2 -->
<div style="border:2px solid #d0d0d0; background:#f5f5f5; padding:15px; width:45%; border-radius:6px; color:#2b2b2b;">
  <b>P₂</b><br><br>
  …<br><br>
  
<div style="border:2px dashed red; padding:6px; border-radius:4px; color:#2b2b2b;">
  wait (<span style="color:red;">mutex1</span>)
  <br>
  wait (<span style="color:green;">mutex2</span>)<br>
  </div>

  &lt;inizio uso disco 2&gt;<br>
<p>…<br></p>
<p>&lt;inizio uso disco 1&gt;<br>
…<br><br></p>
</div>

</div>

<ul>
<li>
<p>In questo caso, supponendo che P2 faccia per <strong>primo</strong> la prima richiesta delle risorse:</p>
<ul>
<li>P1 è <strong>impossibilitato a usare “disco 1”</strong> anche se P2 sta usando “disco 2”.</li>
<li>Si è imposto un ordine di acquisizione delle risorse (a discapito dell’efficienza).</li>
</ul>
</li>
</ul>
<p>Questo tipo di approccio per la gestione PREVENTION non permette l’implementazione di una cooperazione (come anche gli altri approcci) tra processi.</p>
<p>→ implementando il problema produttori consumatori otteniamo che i produttori producono sempre fino a che non terminano. Solo dopo la terminazione dei produttori i consumatori potranno accedere ai dati prodotti.
→ comportamento non richiesto per l’implementazione.</p>
<h2 id="deadlock-avoidance"><a class="header" href="#deadlock-avoidance">Deadlock AVOIDANCE</a></h2>
<p>Nella gestione AVOIDANCE il sistema decide <strong>a tempo di esecuzione</strong> se una richiesta di una risorsa può portare a un deadlock (<strong>prevenzione dinamica</strong>).</p>
<ul>
<li><strong>nessun vincolo a priori</strong> delle risorse</li>
<li>se lo stato attuale delle risorse è <strong>rischioso</strong>, un algoritmo <strong>rifiuta la richiesta</strong> di allocazione</li>
</ul>
<p>Quindi si accetta la possibilità di incorrere in un deadlock, non eliminando le condizione necessarie, ma si cerca di evitarlo valutando lo stato in cui si trova il sistema ogni volta che viene effettuata una richiesta (a <em>run-time</em>).</p>
<p>Quindi istante per istante, possedendo <strong>la storia precedente del grafo delle assegnazioni delle risorse</strong>, un algoritmo valuta se <strong>successivamente</strong> a una certa richiesta da parte di un processo porta l’applicazione a un deadlock.</p>
<p>Quindi l’algoritmo deve essere in grado di fare una <strong>sorta di predizione sull’andamento dell’esecuzione</strong> dei processi negli istanti successivi a una qualsiasi richiesta per una risorsa.</p>
<p>Quindi possiamo considerarla come una prevenzione, che <strong>non è più statica</strong> come per la gestione PREVENTION, ma <strong>dinamica</strong>.</p>
<p>Anche questa come soluzione al deadlock è molto complicata perché richiede diverse assunzioni: come quella di riuscire a prevedere le eventuali richieste di un processo se questo non le dichiara a priori.</p>
<p align="center"><img src="images/avoidance_esempio.png" width="500"></p>

<p>La memoria totale è <code>200 kb</code>.</p>
<ul>
<li>
<p>P2 non avrà accesso alla risorsa nel momento in cui la richiede perché il processo P1 è già in esecuzione e possiede già una istanza della stessa risorsa.</p>
<p>Però il motivo per cui viene rifiutata la richiesta di P2 è perché guardando la storia di P1 si nota che affinché questo possa terminare dovrà ottenere un’altra istanza della risorsa.</p>
<p>Nel momento in cui richiederà un’altra istanza della risorsa non ci sarà più spazio per l’istanza richiesta da P2</p>
<ul>
<li>
<p>Caso in cui avviene il deadlock →  P2 riceva la risorsa (supponendo che successivamente ne richieda un’altra da <code>80 kb</code>).</p>
<p>→ Quindi la memoria in possesso sarà <code>80 + 70 = 150kb</code>.</p>
<p>→ Il processo P1 si sospende perché ne richiede <code>70kb</code> e allo stesso modo si sospende P2 perché ne richiede, come detto, <code>80kb</code>.</p>
<p>→ Entrambi i processi sono sospesi in attesa che l’altro rilasci la risorsa: deadlock.</p>
</li>
</ul>
<p>Nell’esempio un algoritmo ha valutato questa situazione conoscendo la storia di allocazione dei processi.</p>
</li>
</ul>
<p>Quindi è necessario supporre che per ogni processo si deve dichiarare la <strong>storia di allocazione</strong>, altrimenti non di possono fare previsioni sull’andamento dell’esecuzione.</p>
<p>Questo produce un <strong>overhead</strong> elevato sullo sheduler e in generale sul kernel. Ma da una soluzione per non entrare nel deadlock.</p>
<p>Linux implementa ciò? No perché non si conosce a priori la storia di allocazione di ogni processo → è impossibile prevedere un deadlock in questo modo.</p>
<div style="border:3px solid #202092ff; background:#eef1ff; padding:12px; border-radius:6px; color:#555555">
  <b style="color:#d40000;">Presupposto</b>: queste tecniche richiedono di
  <span style="color:#d40000;">conoscere in anticipo</span>
  tutte le richieste che un processo può fare nell’arco della sua esecuzione.
</div>

<p>Questa è un assunzione molto pesante, un caso più semplice di utilizzo è quello che: ogni processo <strong>dichiara</strong> il <strong>numero massimo</strong> di istanze di risorse di cui può avere bisogno.</p>
<p>→ Tali istanze però potrebbero non esser utilizzate subito e quindi tolte ad altri processi che potrebbero sfruttarle immediatamente.</p>
<h3 id="approcci"><a class="header" href="#approcci">Approcci</a></h3>
<p>Abbiamo due diversi approcci per questo tipo di gestione:</p>
<ol>
<li>
<p><strong>Process initiation Denial</strong>: all’avvio di un nuovo processo (rifiuto l’esecuzione del processo)</p>
<p>Non si avvia un processo se le sue richieste potrebbero portare ad un deadlock</p>
</li>
<li>
<p><strong>Resource Allocation Denial</strong>: al momento di una richiesta di allocare una risorsa. (il processo esegue ma possono essere vietate le richieste nonostante la disponibilità corrente è valida)</p>
<p>Si consente l’avvio, ma le richieste di allocazione possono essere rifiutate se possono portare a deadlock.</p>
</li>
</ol>
<hr>
<p>Entrambi questi approcci si basano sulla costruzione di diverse strutture algebriche:</p>
<p>sia <em>n</em> = numero di processi,</p>
<p>e <em>m</em> = numero di tipi di risorse</p>
<ul>
<li>
<p><strong>Resource</strong> = <em>R</em> = (R1, …, Rm)</p>
<p>Risorse totali nel sistema. Ri p il numero di istanze presenti nel sistema per la risorsa i-esima.</p>
</li>
<li>
<p><strong>Available</strong> = <em>V</em> = (V1, …, Vm)</p>
<p>Numero di istanze per ogni risorsa non allocate ad alcun processo. Vi rappresenta il # di istanze della risorsa Ri non ancora allocate.</p>
</li>
<li>
<p><strong>Claim</strong> = <em>C</em> = matrice <em>n x m</em></p>
<p>Cij = richiesta del processo Pi per la risorsa Rj</p>
</li>
<li>
<p><strong>Allocation</strong> = <em>A</em> = matrice <em>n x m</em></p>
<p>Aij = allocazione corrente al processo Pi della risorsa Rj</p>
</li>
</ul>
<hr>
<h3 id="process-initiation-denial"><a class="header" href="#process-initiation-denial">Process Initiation Denial</a></h3>
<ul>
<li>
<p>La matrice <em>C</em> (di richiesta) indica <strong>il numero massimo di richieste</strong> per ogni processo (righe), di una certa risorsa (colonne).</p>
</li>
<li>
<p>Deve essere fornita prima dell’avvio dei processi</p>
<p>Quindi questa matrice verrà aggiornata e ricalcolata ogni volta che un processo termina o inizia la sua esecuzione.</p>
</li>
</ul>
<p align="center"><img src="images/c.png" width="300"></p>

<p>Un processo Pn+1 viene eseguito solo se:</p>
<p align="center" id="legge_numero_richieste_massimo"><img src="images/numero_richieste_massimo.png" width="300"></p>

<p>Cioè un processo viene eseguito se il <strong>numero massimo di richieste di tutti i processi</strong> (sommatoria) <strong>più quelle del nuovo processo</strong> (Cij) per la risorse j-esima è minore del numero di istanze della richiesta Rj.</p>
<p>Questo deve esser calcolato per ogni tipo di risorsa → per ogni colonna di <em>C</em>.</p>
<p>ESEMPIO:</p>
<p align="center"><img src="images/esempio_process_initiation_denial.png" width="600"></p>

<p>In questo esempio P1 non viene eseguito fin tanto che P2 non termina la sua esecuzione (almeno).</p>
<p>Il motivo per cui non viene eseguito è proprio il <a href="#legge_numero_richieste_massimo">vincolo</a> imposto da process initiation denial:</p>
<ul>
<li>
<p>nel momento in cui P1 tenta di esser eseguito.</p>
<p>Per MB di memoria:<br>100 (R1) &gt;= 70 (C11) + 70 (C21) + 0 (C31) = 140 ⟹  non verificato</p>
<p>Per la porta seriale:<br>1 (R2) &gt;= 1 (C12) + 1 (C22) + 0 (C32) = 2 ⟹  non verificato</p>
</li>
</ul>
<h3 id="resource-allocation-denial"><a class="header" href="#resource-allocation-denial">Resource Allocation Denial</a></h3>
<p>Tale approccio viene chiamato anche <strong>algoritmo del banchiere</strong></p>
<p>→ viene eseguito ad ogni tentativo di allocazione;</p>
<ul>
<li>se l’allocazione può portare ad uno stato “non-sicuro” viene rifiutata.</li>
</ul>
<p>L’algoritmo fa in modo che lo stato del sistema (risorse e processi) <strong>non sia mai uno stato non sicuro</strong></p>
<p align="center"><img src="images/stato_sistema.png" width="300"></p>

<p>La <strong>strategia</strong> consiste nel trovare una sequenza di esecuzione <em>safe</em>.<br>La sicurezza di uno stato dipende dalle risorse disponibili, e dalle richieste di tutti i processi nel sistema.</p>
<p align="center"><img src="images/esempio_stato_non_safe.png" width="550"></p>

<p>Quindi l’obiettivo è fare in modo di determinare una sequenza di esecuzione che non faccia mai entrare lo stato del sistema nella porzione del piano <em>unsafe</em>.</p>
<p>ESEMPIO:</p>
<p align="center"><img src="images/esempio_unsafe.png" width="500"></p>

<p>In questo esempio si può vedere la sequenza delle operazioni di richiesta e rilascio delle risorse R1 e R2 per i processi P1 e P2.<br>Si nota subito che questa configurazione <strong>potrebbe</strong> portare ad uno stato non sicuro (deadlock) a run-time (dipende dalla velocità relativa di esecuzione).</p>
<p>Infatti non è detto che possa esserci un deadlock, perché come vediamo l’algoritmo del banchiere ha come risultato due sequenze sicure per lo stato iniziale.<br>→ quindi lo stato iniziale è uno stato sicuro, ciò significa che l’esecuzione potrebbe arrivare a terminare senza il manifestarsi di <strong>deadlock</strong> (se viene seguita una delle sequenze sicure).</p>
<p align="center"><img src="images/esempio_spazio_stato.png" width="600"></p>

<ul>
<li>Il modo in cui sono stati eseguiti i due processi hanno portato lo stato ad essere <strong>non sicuro</strong>, in questo caso è inevitabile il deadlock.</li>
<li>Entrambi i processi resteranno in attesa l’uno dell’altro.</li>
</ul>
<h4 id="sequenza-sicura"><a class="header" href="#sequenza-sicura">Sequenza sicura</a></h4>
<div style="border:3px solid #202092ff; background:#eef1ff; padding:12px; border-radius:6px; color:#555555">
Il sistema è in uno <b style="color:#d40000;"> stato sicuro</b> se, partendo da questo stato, <b style="color:#d40000;">esiste un sequenza sicura</b> di esecuzione di tutti i processi nel sistema.
</div>

<p>Tale sequenza è una sequenza di <strong>esecuzione “ipotetica”</strong> dei processi nel sistema che porta al processo richiedente di una risorsa a terminare la propria esecuzione. (es. Pa, Pb, Pc, …)</p>
<p>(che porta a tutti i processi del sistema a terminare)</p>
<p>Affinché uno stato sia sicuro è sufficiente che esista almeno una sequenza sicura.</p>
<p>L’algoritmo del banchiere prevede proprio di trovare la sequenza sicura che verifichi lo stato corrente, se al processo che ha richiesto una risorsa la ottiene.</p>
<p>Se esiste almeno una sequenza sicura,<br>tale che il processo richiedente possa terminare dopo una serie di terminazioneùi di altri processi.</p>
<p>(tale che tutti i processi del sistema possano terminare dopo una serie finita di terminazioni di altri processi)</p>
<p>→ Allora lo stato <strong>è</strong> <strong>sicuro</strong> e la richiesta viene accettata.</p>
<p>→ Altrimenti se <strong>non esiste</strong> lo stato non sarà sicuro e quindi la richiesta <strong>viene rifiutata</strong>;
il processo si mette in <strong>attesa</strong> e verrà riattivato solo nel momento in cui la sua richiesta porti in uno stato sicuro.</p>
<h4 id="workflow"><a class="header" href="#workflow">workflow</a></h4>
<ul>
<li>
<p>Si parte da uno stato che si suppone esser sicuro.</p>
<p align="center"><img src="images/esempio_resource_allocation_denial/1.png" width="500"></p>

</li>
<li>
<p>Un processo Pa fa una richiesta di istanze di risorsa.</p>
<p align="center"><img src="images/esempio_resource_allocation_denial/2.png" width="500"></p>

</li>
<li>
<p>Dopo tale richiesta si verifica che lo stato sia sicuro, supponendo che la richiesta sia stata accettata.</p>
</li>
</ul>
<p>→ come avviene tale verifica:</p>
<ul>
<li>
<p>si tenta di trovare una sequenza sicura partendo dallo stato in cui la richiesta di Pa sia stata accettata.</p>
<p align="center"><img src="images/esempio_resource_allocation_denial/3.png" width="500"></p>

</li>
<li>
<p>si considera <strong>ogni processo Pi</strong> in esecuzione che necessita dello stesso tipo di risorse (Pa,Pb,Pc);</p>
</li>
<li>
<p>si verifica se il processo Pi possa terminare, con <strong>le risorse disponibili rimanenti</strong>, considerando che la richiesta di Pa sia stata accettata.</p>
<p>Quindi si suppone di assegnare al processo Pi tutte le risorse del suo <strong>claim</strong>, se disponibili.<br>Se c’è disponibilità si suppone che il processo termini e rilasci le risorse possedute;</p>
</li>
</ul>
<div style="
    width: 100%;
    max-width: 750px;          /* larghezza massima, simile alla colonna di testo */
    margin: 0 auto;            /* centra il blocco */
    overflow-x: auto;          /* scroll orizzontale se le img non ci stanno */
    overflow-y: hidden;
    white-space: nowrap;       /* tutte le immagini sulla stessa riga */
    padding-bottom: 10px;
  ">
  <img src="images/esempio_resource_allocation_denial/4.png" style="width: 500px; display: inline-block; margin-right: 20px;">
  <img src="images/esempio_resource_allocation_denial/5.png" style="width: 500px; display: inline-block; margin-right: 20px;">
  <img src="images/esempio_resource_allocation_denial/6.png" style="width: 500px; display: inline-block; margin-right: 20px;">
</div>

<ul>
<li>
<p>se il processo i-esimo riesce a terminare allora potrà essere aggiunto alla <strong>sequenza sicura</strong>; altrimenti si passa al prossimo processo.</p>
<p align="center"><img src="images/esempio_resource_allocation_denial/7.png" width="500"></p>

<ul>
<li>Pc è in grado di terminare quindi viene aggiunto alla sequenza sicura di esecuzione.</li>
<li>Si suppone che dopo la sua terminazione <strong>rilasci</strong> tutte le risorse possedute.<br>→ in modo da permettere ad altri processi di terminare.</li>
</ul>
<p align="center"><img src="images/esempio_resource_allocation_denial/8.png" width="500"></p>

<ul>
<li>Pa riesce a terminare, viene aggiunto alla sequenza sicura.</li>
</ul>
<p align="center"><img src="images/esempio_resource_allocation_denial/9.png" width="500"></p>

<ul>
<li>Anche Pb riesce a terminare.<br>→ Si è trovato una sequenza sicura di esecuzione in cui tutti i processi terminano a valle dell’allocazione di risorse a Pa.</li>
</ul>
</li>
</ul>
<p>Si itera questo procedimento fin quando:</p>
<ul>
<li>il prossimo processo a far parte della sequenza sicura è il processo richiedente, Pa.</li>
<li>A questo punto <strong>termina l’algoritmo con una sequenza sicura di esecuzione</strong>.</li>
</ul>
<p>⟹ la richiesta viene accettata perché lo <strong>stato</strong>, dopo l’allocazione delle risorse al processo Pa, è <strong>sicuro</strong>.</p>
<p align="center"><img src="images/esempio_resource_allocation_denial/10.png" width="500"></p>

<p>oppure</p>
<ul>
<li>se per un’iterazione <strong>non</strong> si trova alcun processo in <strong>grado</strong> <strong>di</strong> <strong>terminare</strong> <strong>completamente</strong>, supponendo di assegnargli tutte le risorse del <strong>claim</strong> (<strong>se disponibili</strong>).</li>
<li>Allora il risultato dell’algoritmo è che non esiste una sequenza sicura.</li>
</ul>
<p>⟹ la richiesta di Pa viene <strong>rifiutata</strong> perché lo stato successivo se la richiesta fosse accettata sarebbe <strong>non sicuro</strong>.<br>Il processo rimane in attesa fin quando la propria richiesta non porti in uno stato sicuro.</p>
<h4 id="caratteristiche-di-una-sequenza-sicura"><a class="header" href="#caratteristiche-di-una-sequenza-sicura">caratteristiche di una sequenza sicura</a></h4>
<p>La sequenza sicura (P1, P2, …, Pn) è un ordine di esecuzione dei processi, tale che:</p>
<ul>
<li>
<p>include <strong>tutti i processi attualmente attivi</strong> nel sistema;</p>
</li>
<li>
<p>ogni processo Pi esegue <strong>completamente</strong>, dopo che tutti i processi precedenti Pj, j &lt; i, abbiano a loro volta <strong>eseguito per intero</strong> e nell’ordine della sequenza;</p>
</li>
<li>
<p>Ogni processo Pi ottiene tutte le risorse del suo <strong>claim</strong>, e le <strong>rilascia</strong> <strong>tutte</strong> al termine della sua esecuzione;</p>
</li>
<li>
<p>ogni processo Pi usa una <strong>quantità di risorse non superiore</strong> alla somma di:</p>
<ul>
<li>risorse <strong>disponibili</strong> nello stato S</li>
<li>risorse <strong>rilasciate</strong> dei processi <strong>precedenti</strong> nella sequenza, Pj con j &lt; i</li>
</ul>
</li>
</ul>
<h4 id="considerazioni"><a class="header" href="#considerazioni">considerazioni</a></h4>
<p>Per un corretto funzionamento è necessario che l’algoritmo sia sempre <strong>eseguito</strong> <strong>ad</strong> <strong>ogni</strong> <strong>tentativo</strong> <strong>di</strong> <strong>allocazione</strong> di risorse.</p>
<p>In ogni momento in cui lo stato cambia, si verifica se esiste almeno una sequenza sicura.</p>
<p>Intuitivamente, l’algoritmo garantisce sempre che <strong>esista almeno una exit strategy</strong> che evita il deadlock.</p>
<p>Questa sequenza sicuro non è detto che sia l’ordine effettivo con cui eseguiranno i processi.</p>
<h4 id="problematiche"><a class="header" href="#problematiche">problematiche:</a></h4>
<ul>
<li>
<p>è richiesto che sia <strong>noto</strong> <strong>preventivamente</strong> il numero <strong>massimo</strong> di risorse che ogni processo utilizzerà;</p>
</li>
<li>
<p>i processi che vengono analizzati dell’algoritmo devono essere indipendenti (non è prevista la sincronizzazione).</p>
<p>Altrimenti il problema si complicherebbe eccessivamente<br>→ si dovrebbe tener conto che un processo possa terminare solo se termini prima un altro processo;</p>
</li>
<li>
<p>deve esser presente un numero predeterminato e costante di risorse da allocare;</p>
</li>
<li>
<p>Tutti i processi devono rilasciare le risorse possedute prima di terminare.</p>
</li>
</ul>
<h2 id="deadlock-detection"><a class="header" href="#deadlock-detection">Deadlock DETECTION</a></h2>
<ul>
<li>
<p>Non vincola le richieste alle risorse, consente il verificarsi del deadlock.</p>
</li>
<li>
<p>Il sistema esegue un algoritmo <strong>per il rilevamento dell’attesa circolare</strong>:</p>
<ul>
<li>periodicamente;</li>
<li>ad ogni richiesta;</li>
<li>quando il grado di uso della CPU è basso.</li>
</ul>
</li>
<li>
<p>In caso affermativo, il sistema applica un algoritmo di <strong>ripristino</strong> (recovery).</p>
</li>
</ul>
<p>La strategia di detection sfrutta il <strong>grafo di attesa</strong>, che è un grafo costruito da quello di assegnazione delle risorse.</p>
<p>Tale grafo rappresenta l’attesa che un processo ha rispetto un altro processo.</p>
<ul>
<li>
<p>Ogni nodo è un processo.</p>
</li>
<li>
<p>Gli archi indicano che un processo è in attesa che un altro processo rilasci la propria risorsa.</p>
</li>
<li>
<p>Periodicamente viene aggiornato e chiamato l’algoritmo per la <strong>ricerca di eventuali cicli di attesa</strong>.</p>
<ul>
<li>Tale algoritmo richiede un numero di operazioni dell’ordine di \(n^2\) , dove <em>n</em> è il numero di vertici (processi).</li>
</ul>
</li>
</ul>
<p align="center"><img src="images/grafo_attesa.png" width="400"></p>

<p>Strategie di ripristino:</p>
<ul>
<li>si <strong>uccidono tutti i processi</strong> in uno stato di deadlock</li>
<li>si esegue un <strong>checkpoint</strong> di uno stato precedente al deadlock e si fanno <strong>ripartire i processi</strong></li>
<li>si <strong>uccide un processo alla volta</strong> fino a quando il deadlock non esiste più</li>
<li>si <strong>prelazionano le risorse</strong> ai processi bloccati fino a quando il deadlock non esiste più</li>
</ul>
<p>Nel caso in cui la strategia prevede l’aborto di un processo in esecuzione, si possono utilizzare diverse metriche per decidere quale tra quelli interessati:</p>
<ul>
<li>minor tempo di CPU consumato fino a quel momento</li>
<li>minor numero di linee di output prodotte finora</li>
<li>maggior tempo stimato per la terminazione</li>
<li>minor numero di risorse allocate finora</li>
<li>minore priorità</li>
</ul>
<p align="center"><img src="images/ricapitolazione.png" width="500"></p>

<div style="break-before: page; page-break-before: always;"></div><script src="../javascript.js"></script>
<h1 id="gestione-della-memoria-1"><a class="header" href="#gestione-della-memoria-1">Gestione della memoria</a></h1>
<p>La <strong>memoria principale</strong> costituisce, insieme la CPU, una delle risorse per realizzare <strong>l’astrazione di processo</strong>.</p>
<p>Il processo dispone di una <strong>area di memoria</strong> ad esso <strong>riservata</strong> (non accessibile da altri processi).<br>Tale area di memoria (<em>memoria virtuale</em>) illude il processo facendogli credere di avere a disposizione <strong>l’intera memoria principale</strong>.</p>
<p>Questa memoria riservata permette a ciascun processo di avere una <strong>vista indipendente</strong> <strong>e continua</strong> della memoria, anche se, fisicamente, la memoria principale è condivisa tra più processi e l’allocazione dell’immagine di questi non è detto che sia continua.</p>
<p>Il sistema operativo, come per il processore, attraverso l’utilizzo dei <strong>PCB</strong> garantisce il principio di <strong>isolamento</strong> tra processi, ovvero è necessario assicurarsi che l’esecuzione di uno non interferisca con quella di un altro.<br>Quindi fisicamente i processi non devono accedere ad aree di memoria fisiche in cui è contenuta l’immagine di un altro processo.</p>
<p align="center"><img src="images/immagine_allocata_in_RAM.png" width="500"></p>

<p>L’immagine del processo è descritta all’interno del PCB dello specifico processo.<br>In questa struttura sono contenute anche informazioni <strong>su dove si trovano</strong> le diverse parti dell’immagine <strong>in memoria centrale</strong>.</p>
<p>I processi non accedono mai direttamente alla memoria principale tramite degli indirizzi.<br>Lavorano invece su una propria <strong>memoria virtuale</strong> (riservata), esso non utilizza indirizzi di memoria fisici ma bensì <strong>virtuali</strong>.</p>
<p>Tali <strong>indirizzi virtuali</strong> hanno senso solo nella visione della memoria del processo → non corrispondono a veri e propri indirizzi della memoria principale.</p>
<hr>
<p>ESEMPIO:</p>
<p>Quando utilizziamo indirizzi all’interno di un codice non stiamo realmente utilizzando indirizzi fisici ma indirizzi virtuali.</p>
<p>Infatti quando stampiamo gli indirizzi di memoria delle variabili che utilizza un processo non stiamo realmente stampando indirizzi di memoria, ma indirizzi di memoria logici.</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
int main() {
    int x = 3;
    printf("location of stack: %p\n", &amp;x);
    char * p = malloc(1024);
    printf("location of heap : %p\n", p);
    printf("location of code : %p\n", main);
}
</code></pre>
<pre><code class="language-console">location of stack: 0x7fff691aea64
location of heap : 0x1096008c0
location of code : 0x1095afe50
</code></pre>
<p>Tali indirizzi virtuali che abbiamo stampato vengono tradotti da un componente hardware (MMU - Memory Management Unit) per eseguire le istruzioni desiderate.</p>
<hr>
<p>Il kernel, a differenza di un Hypervisor, astrae l’hardware per consentire l’esecuzione di un processo in modo indipendente.</p>
<p>La posizione (<strong>indirizzi</strong>) di codice e dati nella memoria di un processo è un’<strong>astrazione</strong>. → indirizzi virtuali.</p>
<p>La posizione effettiva in memoria fisica è <strong>gestita dal sistema operativo</strong>.</p>
<h2 id="aspetti-e-parametri-caratterizzanti-la-gestione-della-memoria"><a class="header" href="#aspetti-e-parametri-caratterizzanti-la-gestione-della-memoria">Aspetti e parametri caratterizzanti la gestione della memoria</a></h2>
<ul>
<li>
<p><strong>Supporto Hardware</strong> per la gestione della memoria, in particolare l’isolamento tra i processi. (MMU)</p>
</li>
<li>
<p><strong>Organizzazione logica</strong> della memoria virtuale, ovvero le diverse sezioni che fanno parte della memoria virtuale di ogni processo.</p>
</li>
<li>
<p><strong>Organizzazione fisica</strong> della memoria principale, ovvero descrive come è allocata in memoria principale l’immagine di ogni singolo processo.</p>
<p>Tale organizzazione è necessaria per capire dall’indirizzo virtuale a quale indirizzo fisico si sta effettivamente accedendo.</p>
</li>
<li>
<p><strong>Dimensione della memoria virtuale</strong> che può essere più <strong>grande della memoria fisica disponibile</strong>.</p>
<p>Quindi il sistema operativo deve fare in modo di emulare la memoria fisica utilizzando la memoria secondaria, per permettere l’esecuzione dei processi che utilizzano più memoria di quanta ne sia disponibile.</p>
</li>
<li>
<p><strong>Rilocazione</strong>:</p>
<p>La rilocazione è un meccanismo che permette di caricare l’immagine di un processo in memoria principale.</p>
<p>Esistono due principali tipi di rilocazione:</p>
<ul>
<li>statica: gli indirizzi vengono definiti al momento della compilazione o caricamento del programma e non possono essere cambiati.</li>
<li>dinamica: gli indirizzi possono essere modificati durante l’esecuzione del programma, ad esempio quando il programma viene riattivato e ritorna nella memoria principale dallo swap.</li>
</ul>
</li>
<li>
<p><strong>Organizzazione dello spazio virtuale</strong></p>
<ul>
<li>spazio virtuale unico: tutta la memoria di un processo è trattata come un’unica area.</li>
<li>spazio virtuale segmentato: la memoria del processo è suddivisa in <strong>segmenti</strong> (ad esempio, codice, dati, stack) che vengono gestiti separatamente.</li>
</ul>
</li>
<li>
<p><strong>Allocazione</strong></p>
<p>Si riferisce alla maniera con cui il sistema operativo assegna la memoria principale ai processi.</p>
<ul>
<li>contigua: i dati di un processo sono collocati in un blocco contiguo di memoria.</li>
<li>non contigua: i dati di un processo possono essere sparsi in diverse aree della memoria, come avviene nella <strong>paginazione</strong>.</li>
</ul>
</li>
<li>
<p><strong>Caricamento</strong></p>
<p>Il caricamento riguarda come i processi vengono caricati in memoria:</p>
<ul>
<li>tutto insieme: il processo viene caricato tutto in una volta nella memoria.</li>
<li>a domanda: solo le parti del processo necessarie vengono caricate in memoria, quando l’esecuzione ne richiede l’accesso.</li>
</ul>
</li>
</ul>
<h2 id="tecniche-di-gestione-della-memoria"><a class="header" href="#tecniche-di-gestione-della-memoria">Tecniche di gestione della memoria</a></h2>
<hr>
<p>Rilocazione significa allocare l’immagine del processo nella memoria principale, può avvenire in diversi modi.</p>
<p>Questa rilocazione può essere statica o dinamica.</p>
<hr>
<p>Nei primi sistemi, il posizionamento del codice e dati è <strong>fisso</strong>. → con asim abbimo inserito in posizioni fisse il codice e i dati.<br>Il processo è caricato in RAM tutto insieme come un <strong>unico blocco</strong> (allocazione contigua).</p>
<p align="center"><img src="images/primi_sistemi_gestione_memoria.png" width="600"></p>

<p>Statica perché era più semplice.</p>
<p>Con l’introduzione di hw più evoluti si è permesso di configurare nella CPU il posizionamento di codice e dati, a <strong>tempo di esecuzione</strong>.<br>→ ad esempio sfruttando una base e un offset per determinare l’indirizzo fisico.</p>
<p>Con il supporto dei compilatori, la memoria del processo è divisa in blocchi (segmenti) che possono essere <strong>gestiti in maniera separata e indipendente dal SO</strong>.<br>Ad esempio il SO protegge il segmento dedicato al codice dando il permesso di sola lettura all’area di memoria a cui sarà destinato.</p>
<p align="center"><img src="images/evoluzione_hw.png" width="600"></p>

<p>Ulteriori evoluzioni hw hanno permesso di <strong>caricare</strong> l’immagine del processo (o un suo segmento) <strong>non più per intero</strong>, ma in <strong>piccole porzioni (pagine)</strong> ( caricamento a domanda) <strong>sparpagliate</strong> in memoria fisica (allocazione non contigua).</p>
<p>Quindi è stata introdotta l’allocazione di tipo <strong>non contigua</strong> grazie allo sviluppo dell’hardware MMU.</p>
<p>Che vantaggio mi da l’accolazione di tipo non contigua?<br>→ uso efficiente dell’area di memoria in termini di <strong>flessibilità e dinamicità</strong>; i processi non devono essere necessariamente allocati in un blocco contiguo di memoria.<br>→ attenua il <strong>problema della frammentazione</strong>, perché non ho bisogno di trovare una area di memoria di dimensione tale da contenere interamente l’immagine del processo. Ci sono due tipi principali di frammentazione:</p>
<ul>
<li>frammentazione interna: si verifica quando la memoria allocata per il processo <strong>è più grande di quella effettivamente necessaria</strong>.</li>
<li>frammentazione esterna: si verifica quando ci sono <strong>molti piccoli spazi liberi sparsi</strong> nella memoria fisica, ma <strong>nessuno</strong> di questi <strong>è abbastanza grande da ospitare un nuovo processo</strong>.</li>
</ul>
<p align="center"><img src="images/introduzione_MMU.png" width="600"></p>

<ul>
<li><strong>Partizioni fisse</strong>: memoria suddivisa in blocchi di <strong>dimensione fissa</strong>. Facile da gestire ma potrebbe causare <strong>frammentazione interna</strong>.</li>
<li><strong>Partizioni variabili</strong>: la memoria virtuale viene allocata in blocchi di <strong>dimensioni variabili</strong> a seconda delle necessità del processo. Riduce la frammentazione interna ma può comunque portare a <strong>frammentazione esterna</strong>.</li>
<li><strong>Partizioni multiple</strong>: una combinazione di partizioni fisse e variabili.</li>
<li><strong>Segmentazione a domanda</strong>: caricamento dinamico di segmenti di processi solo quando necessari. Ottimizza l’uso della memoria, ma può causare ritardi nei processi se la memoria virtuale deve essere frequentemente caricata dal disco.</li>
</ul>
<!-- @todo aggiungi paginazione e segmentazione con paginazione -->
<h2 id="rilocazione"><a class="header" href="#rilocazione">Rilocazione</a></h2>
<p>Modalità di allocazione dei dati e del codice di un processo in memoria fisica.</p>
<p>L’associazione di <strong>istruzioni e dati</strong> ad indirizzi di memoria (fisica) si può compiere in ognuna delle sequenti fasi:</p>
<ul>
<li>
<p><strong>compilazione</strong>: se nella fase di compilazione si conosce dove il processo risiederà nella memoria, allora può <strong>inserire direttamente gli indirizzi fisici nel codice oggetto</strong>.</p>
<p>→ si genera così <strong>codice assoluto</strong>: gli indirizzi nel codice oggetto sono indirizzi fisici reali della RAM. Quindi codice e dati saranno allocati sempre in tali posizioni ad ogni esecuzione.</p>
<p>→ potrebbe essere un problema se il SO decidesse di caricare il programma in un’altra zona della memoria. Sarebbe necessaria una ricompilazione perché tutti gli indirizzi sarebbero <strong>sbagliati</strong>.</p>
<p>Quindi in questo caso gli indirizzi sarebbero fissati per sempre (fino ad una successiva ricompilazione)<br>→ nessuna <strong>flessibilità</strong>;</p>
</li>
<li>
<p><strong>caricamento</strong>: se nella fase di compilazione non è possibile sapere in che punto della memoria risiederà il processo, il compilatore deve generare <strong>codice rilocabile</strong>.</p>
<p>Quindi il <strong>compilatore</strong> <strong>non</strong> <strong>inserisce</strong> nel codice oggetto <strong>indirizzi fisici</strong> ma dei valori relativi che il loader dovrà sistemare.</p>
<p>Quando il processo viene caricato in memoria, il <strong>loader sceglie un indirizzo di partenza</strong> e scorre il codice oggetto aggiustando tutti gli altri indirizzi relativi.</p>
<p>→ dopo il caricamento, lo spazio di indirizzamento del processo non può più esser spostato, altrimenti andrebbero aggiornati tutti gli indirizzi fisici;</p>
</li>
<li>
<p><strong>esecuzione</strong>: se durante l’esecuzione il processo può essere spostato da un segmento di memoria ad un altro, è necessario che si ritardi l’associazione degli indirizzi fino alla fase di esecuzione. (rilocazione dinamica)</p>
<p>→ Qui entriamo in merito della <strong>memoria virtuale</strong> che permette al SO di:</p>
<ul>
<li>spostare un processo in RAM;</li>
<li>fare swapping su disco;</li>
<li>caricare pezzi di processo dove capita (dove si ha disponibilità) → utilizzo efficiente della memoria.</li>
</ul>
<p>Per permettere ciò <strong>non conviene</strong> fissare gli indirizzi fisici <strong>né a compilazione, né al caricamento</strong>.<br>Allora cosa accade:</p>
<ul>
<li>nel codice non vengono inseriti indirizzi fisici ma <strong>logici</strong>;</li>
<li>ogni volta che la CPU fa un accesso a memoria, interviene la <strong>MMU</strong> che traduce gli indirizzi logici nei corrispettivi indirizzi fisici a run-time.</li>
</ul>
<p>Se il processo viene spostato, basta cambiare il <strong>modo</strong> con cui la MMU traduce gli indirizzi.</p>
<p>Quindi per realizzare questo schema sono necessarie specifiche caratteristiche dell’architettura → MMU</p>
</li>
</ul>
<h3 id="statica"><a class="header" href="#statica">statica</a></h3>
<p>La rilocazione statica stabilisce gli indirizzi di codice e dati <strong>al momento della compilazione o caricamento</strong>.</p>
<p>La posizione del codice e dei dati <strong>non può più essere modificata</strong> a tempo di esecuzione.<br>→ nella programmazione in assembly si decide a priori dove il codice viene posizionato in memoria centrale.</p>
<p align="center"><img src="images/rilocazione_statica.png" width="550"></p>

<p>Il problema di questo tipo di rilocazione si presenta nel <strong>context switch</strong>: il processo quando viene prelazionato e inserito nella coda dei processi pronti oppure swappato<br>→nel momento della sua successiva esecuzione deve trovarsi sempre nella stessa area di memoria, altrimenti tutti gli indirizzi fisici su cui lavora sarebbero sbagliati.<br>Questo è un grande <strong>onere computazionale</strong> affidato al sistema operativo.</p>
<p>Quindi con una rilocazione statica è il compilatore o il caricatore ad inserire degli indirizzi fisici all’interno rispettivamente del codice oggetto o del codice eseguibile.</p>
<p align="center"><img src="images/rilocazione_statica_1.png" width="600"></p>

<p>Questi indirizzi non potranno esser cambiato al meno che il codice non venga ricompilato oppure ricaricato.</p>
<h3 id="dinamica"><a class="header" href="#dinamica">dinamica</a></h3>
<p>Con questo approccio, dinamico, l’indirizzo di codice/dati nella immagine (<em>virtuale</em>) <strong>non corrisponde</strong> alla loro posizione effettiva in RAM (<em>indirizzo fisico</em>).</p>
<p>L’effettiva posizione dello spazio di indirizzamento del processo è <strong>scelta da SO</strong>, al caricamento iniziale del processo, o anche durante la sua esecuzione.</p>
<p>→ richiede un supporto hardware che permetta a tempo di esecuzione di tradurre gli indirizzi virtuali in indirizzi fisici.</p>
<p>Infatti la rilocazione di tipo dinamico si introduce un distinzione fondamentale:</p>
<ul>
<li>
<p><strong>Indirizzo virtuale</strong>:</p>
<p>indirizzo <strong>acceduto dal programma</strong> durante l’esecuzione.</p>
</li>
<li>
<p><strong>Indirizzo fisico</strong>:</p>
<p>indirizzo visto dall’unità di memoria, <strong>posizione effettiva</strong> del dato/istruzione.</p>
</li>
</ul>
<p>Quando otteniamo <strong>segmentation fault</strong> significa che l’indirizzo virtuale che stiamo utilizzando, erroneamente, non è associato ad un indirizzo fisico facente parte dell’immagine del processo nella memoria fisica → l’indirizzo fisico che stiamo deferenziando non è mappato nella memoria virtuale.<br>→ la traduzione da indirizzo virtuale a indirizzo fisico ha dato questo problema.</p>
<p>Vedremo che il fault può essere <strong>ripristinabile</strong>, perché il segmento/pagina non sono in memoria fisica ma sono swappati in memoria di massa. → ci troviamo nella situazione di un caricamento a domanda.</p>
<p>Il processore vede solo indirizzi logici (virtuali)<br>→ <strong>tradotti dall’hardware</strong> che ha la visibilità della memoria fisica, ovvero MMU.<br>MMU rende trasparente l’accesso del processore agli indirizzi fisici.</p>
<p>Se non fosse così il processore <strong>sarebbe più performante</strong> (vedrebbe direttamente gli indirizzi fisici), ma perderei tutta la parte di virtualizzazione.</p>
<p>Infatti come abbiamo visto, aprendo il file eseguibile od oggetto, non sono presenti indirizzi fisici ma unicamente indirizzi virtuali che solitamente partono tutti da <code>0x0</code>.</p>
<p align="center"><img src="images/rilocazione_dinamica.png" width="550"></p>

<h4 id="vantaggi-della-rilocazione-dinamica"><a class="header" href="#vantaggi-della-rilocazione-dinamica">Vantaggi della rilocazione dinamica</a></h4>
<p>La rilocazione dinamica consente lo <strong>swapping</strong></p>
<ul>
<li>un processo è temporaneamente <strong>sospeso</strong> e trasferito in <strong>memoria secondaria</strong>;</li>
<li>il processo potrà poi essere ri-caricato in un’<strong>area</strong> di <strong>memoria</strong> <strong>differente</strong>, in base alla situazione attuale della memoria.</li>
</ul>
<h4 id="mmu-memory-management-unit"><a class="header" href="#mmu-memory-management-unit">MMU (Memory Management Unit)</a></h4>
<p>MMU è un componente hardware della CPU che ha il compito di rendere <strong>trasparente l’accesso al processore</strong> alla memoria fisica tramite una traduzione di <strong>indirizzi virtuali</strong> (utilizzati dal processore) <strong>in indirizzi fisici</strong>.</p>
<p>ESEMPIO DI RILOCAZIONE DINAMICA:</p>
<p>Caso basilare (obsoleto):</p>
<ul>
<li>spazio virtuale unico → viene trattato come un unica area.</li>
<li>allocazione contigua → viene allocato in memoria tutto insieme.</li>
</ul>
<p>MMU in questo caso possiamo rappresentarla come un componente hardware avente due registri speciali: <strong>limite</strong> e <strong>base</strong>.</p>
<p>In questo caso banale la traduzione avviene con la somma tra l’indirizzo virtuale + la base, ovviamente a valle di una verifica sull’indirizzo virtuale (se esiste un indirizzo fisico mappato con tale indirizzo virtuale).</p>
<p align="center"><img src="images/caso_obsoleto.png" width="550"></p>

<p>Ovviamente dobbiamo prevedere un modo per modificare i registri dell’MMU, che sono specifici per ogni processo.</p>
<p>Oltre a cambiare valore per ogni processo i due registri devono esser modificati anche ogni volta che un processo passa in esecuzione da che era swappato<br>→ con la rilocazione dinamica potrebbe ritrovarsi in una posizione della memoria fisica differente alla precedente</p>
<p>Questo modello infatti non è la realtà, è uno schema di funzionamento base dell’MMU.</p>
<h2 id="caricamento-unico-e-a-domanda"><a class="header" href="#caricamento-unico-e-a-domanda">Caricamento unico e a domanda</a></h2>
<p>Il caricamento in memoria dell’immagine del processo è fatta dal <strong>loader</strong> che è parte del SO che:</p>
<ul>
<li><strong>legge</strong> l’eseguibile (e.g. ELF);</li>
<li><strong>alloca</strong> memoria per il processo;</li>
<li><strong>mappa</strong> gli indirizzi virtuali negli indirizzi fisici (a seconda della rilocazione utilizzata: statica o dinamica);</li>
<li><strong>copia</strong> in RAM le parti necessarie del programma (<strong>a seconda della tipologia di caricamento</strong>);</li>
<li><strong>prepara</strong> il processo per la prima esecuzione → ad esempio, crea il PCB.</li>
</ul>
<p>Nella fase di copia il loader si può comportare in due modi a seconda della tipologia di caricamento implementata:</p>
<ul>
<li>
<p>Nel <strong>caricamento unico</strong> (tutto insieme)</p>
<ul>
<li>Il loader carica tutta l’immagine del programma in memoria RAM.</li>
</ul>
<p>Questo è un approccio tipico dei vecchi sistemi o microcontrollori.</p>
</li>
<li>
<p>Nel <strong>caricamento a domanda</strong> (demand loading)</p>
<ul>
<li>Il loader crea solo le mappature virtuali → fisiche.</li>
<li>Il caricamento effettivo del codice/dati avviene <strong>solo quando necessario</strong>.</li>
<li>La MMU genera un fault quando la <strong>CPU tenta di accedere a una parte del processo che NON è ancora stata caricata in memoria fisica</strong>.</li>
</ul>
<p>A questa fault generata (<strong>interruzione sincrona</strong>), il SO chiama un handler che fa una recovery. Ovvero verifica se tale parte di processo a cui voule accedere la CPU è presente in memoria secondaria e la carica, permettendo al processore di proseguire con l’esecuzione.</p>
<p>Se tale parte non viene trovata viene rilanciata ancora la fault che in questo caso genera la terminazione del processo → ha tentato di accedere ad un indirizzo di memoria che non fa parte del proprio spazio di indirizzamento.</p>
<blockquote>
<p>NOTA: fault è un tipo di interruzione sincrona perché viene chiamata nel momento in cui nella tabella delle pagine o segmenti non è stata mappata la pagina virtuale in una fisica.
<strong>NON è asincrona</strong>.</p>
</blockquote>
</li>
</ul>
<h2 id="gestione-dello-spazio-virtuale"><a class="header" href="#gestione-dello-spazio-virtuale">Gestione dello spazio virtuale</a></h2>
<p>Vi sono due possibili approcci per gestire lo <strong>spazio virtuale</strong> degli indirizzi.</p>
<ul>
<li>Uno <strong>spazio unico</strong><br>(corrispondente all’intero processo)</li>
<li>Un insieme di <strong>segmenti</strong><br>(<strong>segmentazione</strong> → la memoria del processo è gestita in porzioni separate)</li>
</ul>
<p align="center"><img src="images/approcci_spazio_virtuale.png" width="500"></p>

<p>Nell’approccio segmentato l’immagine del processo è suddivisa in <strong>porzioni logiche</strong> (segmenti) gestite in modo separato ed indipendente dal sistema operativo.<br>Ogni segmento può avere una dimensione variabile, in base alla struttura logica del programma (codice, heap, stack, dati).</p>
<p><strong>Vantaggio principale</strong>:<br>La segmentazione facilita la condivisione di aree di memoria fisica tra più processi, mappandole in segmenti distinti del loro spazio di indirizzamento.\</p>
<ul>
<li>→ Esempio:<br>il segmento di codice (text) di un programma è di sola lettura.<br>Più processi che eseguono lo stesso programma possono <strong>condividere la stessa copia fisica</strong> del codice, mappandola nel proprio spazio di indirizzamento virtuale all’interno del segmento dedicato all’area testo.</li>
</ul>
<h2 id="segmentazione"><a class="header" href="#segmentazione">segmentazione</a></h2>
<div style="display: flex;">
<div>
A <b>tempo di compilazione</b>, si configura lo spazio virtuale segmentato.
<p>Viene creato un diverso <strong>segmento</strong> per ciascun <strong>modulo</strong> del programma.</p>
<hr>
<h4 id="vantaggi-della-segmentazione"><a class="header" href="#vantaggi-della-segmentazione">vantaggi della segmentazione</a></h4>
<ul>
<li><strong>Protezione</strong> dei segmenti;<br>permette una <strong>granularità fine</strong> nella gestione dei permessi sullo spazio di indirizzamento.<br>Ad ogni segmento può avere <strong>permessi diversi</strong> (lettura, scrittura, esecuzione).</li>
</ul>
</div>

<p align="center"><img src="images/segmenti_per_moduli.png" width="300"></p>

</div>

<ul>
<li>
<p><strong>Condivisione</strong> dei segmenti;<br>segmenti come <strong>codice</strong> (text) o le <strong>librerie</strong> <strong>condivise</strong> possono essere mappate da più processi e condividere un’unica copia fisica, <strong>riducendo l’uso della memoria</strong>.</p>
</li>
<li>
<p><strong>Allocazione indipendente</strong> dei segmenti in memoria fisica → riduce (ma non elimina) il problema della frammentazione.<br>Ogni segmento può essere <strong>collocato separatamente in punti diversi</strong> della memoria fisica.</p>
</li>
</ul>
<hr>
<p>Un indirizzo virtuale è una coppia (contiene due informazioni), fatta da:</p>
<ul>
<li>un <strong>identificativo</strong> del segmento;</li>
<li>uno <strong>scostamento</strong> (offset) all’interno del segmento.</li>
</ul>
<p align="center"><img src="images/info_indirizzi_virtuali.png" width="600"></p>

<p>L’<strong>MMU</strong> è il componente su cui si basa anche la segmentazione.</p>
<ul>
<li>Traduce gli indirizzi virtuali dalla forma (<em>segmento</em>, <em>offset</em>) in indirizzi fisici.</li>
<li>Nel caso di <strong>pochi segmenti</strong>, è sufficiente avere nella MMU più coppie di registri base/limite: uno per ogni segmento.</li>
</ul>
<p>Questo è un <strong>limite</strong> fisico importante perché non mi permetterebbe di avere molti segmenti. → non posso avere un numero infinito di registri.</p>
<hr>
<p>ESEMPIO SEGMENTAZIONE CASO SEMPLICE:</p>
<p align="center"><img src="images/MMU_multi_registro.png" width="500"></p>

<ul>
<li>in questo caso ogni coppia di registri corrisponde a limite e base per un segmento allocato in memoria fisica</li>
<li>l’identificativo <code>sg</code> servirà per capire a quale tipologia di segmento accedere facendo riferimento alla giusta coppia D, I</li>
<li>l’offset (<code>off</code>) sarà sommato al corretto registro base I se &lt;= del registro limite D corrispondente ad un segmento, altrimenti la MMU solleverà un eccezione (segmentation fault).</li>
</ul>
<hr>
<p>Nel caso <strong>generale</strong>, quando si vuole supportare un <strong>numero arbitrario di segmenti</strong>, non è possibile avere una coppia <strong>base/limite</strong> nella MMU per ogni segmento di un processo.</p>
<p>Per questo motivo:</p>
<ul>
<li>le coppie base/limite non risiedono nella MMU, ma sono memorizzare in <strong>memoria RAM</strong>;</li>
<li>queste informazioni sono raccolte in una struttura dedicata, chiamata <strong>tabella dei segmenti (segment table)</strong> unica <strong>per ogni processo</strong>;</li>
<li>ogni <strong>entry</strong> della tabella dei segmenti contiene i dati relativi a un <strong>segmento del processo</strong>: <strong>indirizzo base</strong>, <strong>limite</strong> e <strong>bit di controllo</strong> (permessi rwx).</li>
</ul>
<p>La MMU gestisce la segment table con due appositi <strong>registri</strong>:</p>
<ul>
<li><strong>STBR</strong> (Segment Table Base Register): indirizzo in memoria fisica in cui si trova la tabella dei segmenti.</li>
<li><strong>STLR</strong> (Segment Table Limit Register): dimensione della tabella dei segmenti (indica il <strong>numero di segmenti del processo</strong>)</li>
</ul>
<p>Il SO, all’atto del caricamento in memoria del processo da eseguire, imposterà l’<strong>indirizzo fisico</strong> dell’<em>entry point</em> della <em>segment table</em> nel registro <strong>STBR</strong>.<br>Tale indirizzo essendo strettamente legato al processo, è contenuto all’interno del PCB.</p>
<hr>
<p>ESEMPIO DI TRADUZIONE UTILIZZANDO LA SEGMENT TABLE:</p>
<p align="center"><img src="images/trad_segment_table.png" width="600"></p>

<ul>
<li><code>sg</code> è l’offset per identificare l’entry point relativo ad un segmento.</li>
<li>Per accedere alla tabella il processore utilizza le informazioni contenute in <code>STBR</code> e <code>STLR</code>  i cui valori sono contenuti all’interno del PCB di ogni processo.</li>
</ul>
<hr>
<p>NOTA sulla segment table:</p>
<ul>
<li>ogni processo ha una <strong>segment table differente</strong></li>
<li>i registri STBR/STLR sono configurati ad ogni <strong>context switch</strong> dei processi<br>→ durante il context switch il SO carica i valori di STBR/STLR dal <strong>PCB del processo</strong> (sono legati al singolo processo).</li>
</ul>
<p align="center"><img src="images/contex_ST.png" width="600"></p>

<h4 id="protezione"><a class="header" href="#protezione">protezione</a></h4>
<p>Ogni segmento può avere diversi <strong>permessi di accesso</strong> specificati da bit di controllo contenuti nella segment table.</p>
<ul>
<li>Ogni riga della segment table di un processo contiene per ogni entry anche una sequenza di <strong>bit di controllo</strong> per gestire i permessi sull’area di memoria in cui è mappato il segmento.</li>
<li>MMU produce una <strong>exception</strong> se il programma non rispetta i permessi.</li>
</ul>
<p align="center"><img src="images/entry_bit.png" width="400"></p>

<h4 id="condivisione"><a class="header" href="#condivisione">condivisione</a></h4>
<p>La segmentazione consente la <strong>condivisione dei segmenti</strong> tra più processi, allocando in memoria fisica una sola copia del segmento.</p>
<p>Abbiamo due processi con le rispettive tabelle dei segmenti.</p>
<p>→ Se hanno una entry in comune significa che i due processi possono accedere alla stessa area di memoria fisica.<br>Quindi stanno effettivamente condividendo la copia del segmento di memoria. Questo permette di allocare una sola copia del segmento in memoria.</p>
<p align="center"><img src="images/condivisione_segmento.png" width="500"></p>

<h4 id="allocazione"><a class="header" href="#allocazione">allocazione</a></h4>
<p>Uno spazio/segmento di memoria virtuale può essere <strong>collocato in memoria fisica</strong> in due possibili modi:</p>
<ul>
<li>
<p>allocazione <strong>contigua</strong>:</p>
<p>lo spazio/segmento è <strong>copiato per intero</strong>, in un intervallo di memoria fisica agli indirizzi [D;D+I]</p>
</li>
<li>
<p>allocazione <strong>non contigua</strong> (<strong>paginazione</strong>)</p>
</li>
</ul>
<h5 id="allocazione-contigua"><a class="header" href="#allocazione-contigua">allocazione contigua</a></h5>
<ul>
<li>
<p>Il SO colloca il proprio blocco di memoria virtuale, e quelli dei processi, in intervalli <strong>non-sovrapposti</strong> della memoria fisica</p>
</li>
<li>
<p>Quando un processo termina, la memoria fisica occupata si libera, creando un <strong>hole</strong></p>
</li>
<li>
<p>Quando un nuovo processo viene caricato, occorre <strong>cercare un hole sufficientemente grande</strong> da contenerlo</p>
<p>→ compito dello sheduler a medio termine.</p>
</li>
</ul>
<p align="center"><img src="images/allocazione_contigua.png" width="600"></p>

<p>Questo è un esempio su come facilmente si può arrivare ad un problema di <strong>frammentazione esterna</strong> della memoria.</p>
<p>Se ci sono <strong>più buchi liberi</strong>, ci sono vari criteri per scegliere dove collocare un segmento:</p>
<ul>
<li><strong>first-fit</strong>: si assegna il <strong>primo</strong> hole sufficientemente grande;</li>
<li><strong>best-fit</strong>: si assegna lo hole <strong>più piccolo</strong> tra quelli sufficientemente grandi per contenere lo spazio di indirizzamento del processo;</li>
<li><strong>worst fit</strong>: si assegna lo hole più grande.</li>
</ul>
<p>In generale, gli <strong>schemi a partizione di dimensione variabile</strong> soffrono del problema della frammentazione esterna.</p>
<p><strong>Frammentazione esterna</strong>: spazio di memoria perduto sotto forma di spezzoni.</p>
<ul>
<li>Lo spazio di memoria totale sarebbe sufficiente per soddisfare una richiesta, <strong>ma non è contiguo</strong>.</li>
<li>→ non si sfrutta a pieno la quantità di memoria totale a disposizione.</li>
</ul>
<p>Dualmente gli schemi a partizione di dimensione fissa soffrono del problema della frammentazione interna.</p>
<p><strong>Frammentazione interna</strong>: è un concetto relativo al singolo segmento, in particolare è legato alla dimensione di questo.</p>
<p>Se i segmenti hanno una dimensione fissa, non è detto che l’immagine di un processo sia un multiplo di questa dimensione. Quindi tale immagine potrebbe occupare un numero di segmenti, ma non tutte le word di questi segmenti avranno un significato.</p>
<p>Ovvero siamo sprecando una porzione dell’ultimo segmento in cui è contenuta l’immagine del processo.</p>
<p align="center"><img src="images/frammentazione_interna.png" width="550"></p>

<h2 id="paginazione"><a class="header" href="#paginazione">Paginazione</a></h2>
<p>La segmentazione oggi non viene più utilizzata.</p>
<p>Invece viene utilizzata la paginazione perché permette di eliminare un enorme problema: la frammentazione esterna.</p>
<p>Ovviamente non è perfetto come approccio infatti anche questo introduce un problema, quello di frammentazione interna. → perdo mediamente per ogni pagina una quantità di memoria pari alla metà della dimensione della pagina stessa.</p>
<p><strong>Paginazione</strong>:</p>
<ul>
<li>
<p>tecnica di allocazione <strong>non contigua</strong> → se fosse contigua la paginazione non avrebbe senso;</p>
</li>
<li>
<p>lo spazio virtuale è diviso in <strong>blocchi di dimensione fissa</strong>;</p>
</li>
<li>
<p>evita la frammentazione esterna;</p>
</li>
<li>
<p>introduce la frammentazione interna.</p>
<p>A causa del fatto che lo spazio virtuale è suddiviso e quindi caricato in memoria fisica all’interno di blocchi di dimensione <strong>fissa</strong>.</p>
</li>
</ul>
<p align="center"><img src="images/associazione_pag_vir_fis.png" width="500"></p>

<ul>
<li>La <strong>tabella delle pagine</strong> è salvata in RAM e come per la segmentazione l’<em>entry point</em> è memorizzato nel PCB di ogni processo.</li>
<li>Ogni processo ha la propria tabella delle pagine.</li>
</ul>
<p>Come detto questo approccio è soggetto alla frammentazione interna.</p>
<p align="center"><img src="images/frammentazione_int.png" width="500"></p>

<ul>
<li>La pagina associata all’ultima pagina della memoria virtuale non è completamente utilizzata.<br>→ spreco della memoria, perché non è possibile più utilizzarla fino a quando non viene deallocata.</li>
</ul>
<p>Cosa accade nel momento in cui si verifica una frammentazione interna:</p>
<ul>
<li>spazio di memoria perso per un blocco assegnato ma non utilizzato a pieno</li>
<li>si verifica se la dimensione del processo non è un multiplo esatto della dimensione dei blocchi</li>
</ul>
<p>Questo fenomeno è tanto <strong>più trascurabile</strong> quanto <strong>più piccola è assegnata la dimensione</strong> di ogni pagina.</p>
<blockquote>
<p>Tipicamente, la <strong>dimensione di pagina</strong> è una potenza di 2, compresa tra 512 byte e 16 MB.</p>
</blockquote>
<h3 id="traduzione-degli-indirizzi"><a class="header" href="#traduzione-degli-indirizzi">Traduzione degli indirizzi</a></h3>
<p>Essendo l’allocazione non contigua è necessario memorizzare ogni pagina virtuale in che posizione della memoria fisica si trova.</p>
<p>Nel codice, quindi, si utilizzano indirizzi virtuali che devono essere <strong>tradotti dall’MMU</strong> in indirizzi fisici a <em>run-time</em>.</p>
<p>Questo hardware è necessario perché nell’approccio di allocazione <strong>non contigua non si conosce a priori dove sarà rilocato il codice</strong>.<br>→ dobbiamo sempre tener conto che se parliamo di paginazione allora stiamo parlando di allocazione non contigua, altrimenti la paginazione non avrebbe senso.</p>
<p>Quindi quando l’architettura utilizza l’approccio di paginazione, tutti i programmi utilizzano indirizzi virtuali.</p>
<p>La paginazione, inoltre, non è solo una tecnica di allocazione non contigua, ma anche una tecnica per la <strong>gestione della memoria virtuale</strong>. In altre parole, la paginazione permette di creare uno spazio virtuale più grande della memoria fisica, se la gestione del caricamento delle pagine è della tipologia: <strong>a domanda</strong>.</p>
<p>Un indirizzo virtuale contiene la <strong>coppia</strong>:</p>
<ul>
<li><strong>numero di pagina (p)</strong>:<br>identifica una pagina nella memoria fisica → nel contesto di un processo.</li>
<li><strong>scostamento di pagina(d)</strong>:<br>indica la posizione dell’indirizzo all’interno della pagina.</li>
</ul>
<p><strong>A differenza della segmentazione</strong>, non sono due valori separati, ma sono contenuti entrambi in un <strong>unico valore</strong>.<br>→ Nel constesto della CPU, ovvero questa vede un unico indirizzo le cui informazioni non le tratta separatamente.</p>
<p>ESEMPIO: indirizzo virtuale a <strong>16bit</strong>: <code>0x0803</code></p>
<p align="center"><img src="images/indirizzo_paginazione.png" width="470"></p>

<p>Quindi l’indirizzo viene diviso in due campi ognuno dei quali porta con se un’informazione.</p>
<p>Vediamo come avviene la traduzione con l’utlizzo dell’MMU sulla <em>page table</em>.</p>
<p align="center"><img src="images/traduzione_pag.png" width="500"></p>

<p>L’MMU valuta in che posizione si trova l’indirizzo base della pagina identificata da <code>p</code> e utilizza tale indirizzo <code>f</code> sommato all’offset <code>d</code> per ottenere la traduzione in indirizzo fisico.</p>
<p>Ovviamente saranno presenti condizioni che bloccano i casi in cui si eccede dalla tabella delle pagine con <code>p</code>.</p>
<h3 id="tabella-delle-pagine"><a class="header" href="#tabella-delle-pagine">Tabella delle pagine</a></h3>
<p>La tabella delle pagine ha una riga per <strong>ogni pagina virtuale</strong> del <strong>processo</strong>.</p>
<p>All’interno di questa riga sono contenuti:</p>
<ul>
<li>indice della <strong>pagina fisica</strong>,</li>
<li><strong>bit di gestione</strong> (permessi di accesso, etc.).</li>
</ul>
<p>Ovviamente quando si tenta di operare su una pagina l’MMU verifica che il programma non violi i permessi presenti su tale.<br>→ in caso di violazione solleva un <strong>page fault</strong>.</p>
<p align="center"><img src="images/permessi_page_table.png" width="500"></p>

<p>La tabella delle pagine è in <strong>memoria principale</strong>.<br>La MMU usa 2 registri utilizzarla:</p>
<ul>
<li><strong>PTBR</strong> (Page-Table Base Register):
indirizzo fisico della tabella delle pagine in memoria fisica.</li>
<li><strong>PTLR</strong> (Page-Table Length Register):<br>dimensione della tabella delle pagine.</li>
</ul>
<p>Questi due valori sono contenuti all’interno del PCB di ogni processo e vengono caricati in tali registri ogni volta che avviene un <strong>context switch</strong>.</p>
<p align="center"><img src="images/PTBR_PTLR.png" width="480"></p>

<h3 id="architettura-di-paginazione-con-tlb"><a class="header" href="#architettura-di-paginazione-con-tlb">architettura di paginazione con TLB</a></h3>
<p>Per accedere ad ogni singolo dato nella memoria quindi servono <strong>due accessi</strong>.</p>
<ol>
<li>per <strong>leggere la tabella delle pagine</strong></li>
<li>per <strong>accedere al dato/istruzione</strong> vero e proprio</li>
</ol>
<p>Questo provoca un <strong>rallentamento</strong> degli accessi a memoria.</p>
<p>Per <strong>migliorare l’efficienza</strong>, si usa una <strong>cache associativa</strong> detta <strong>TLB</strong> (Translation Look-aside Buffer) che si trova all’interno dell’MMU.</p>
<p>La ricerca di un valore in tale cache associativa ha complessità O(1) → costante.</p>
<!-- @todo da chiedere perché è lineare -->
<p align="center"><img src="images/TLB.png" width="600"></p>

<ul>
<li>
<p>Si possono verificare due situazioni:</p>
<ul>
<li>L’accesso alla TLB produce un cache hit, quindi subito ho l’entry point della pagina in memoria fisica, tale operazione richiede nanosecondi.</li>
<li>L’accesso alla TLB produce un cache miss, quindi la ricerca passa sulla tabella delle pagine, tale operazione richiede decine di nanosecondi.</li>
</ul>
<p>In ogni caso dovrò fare più di un accesso per ottenere il dato/istruzione nella memoria fisica.</p>
</li>
</ul>
<h4 id="tempo-effettivo-di-accesso"><a class="header" href="#tempo-effettivo-di-accesso">Tempo effettivo di accesso</a></h4>
<p><strong>Tasso di successo</strong> (hit ratio, <strong>ɑ</strong>): percentuale di volte che un numero di pagina virtuale si trova nel TLB.</p>
<p>Supponiamo che:</p>
<ul>
<li>Lookup associativo = <strong>ε</strong> unità di tempo</li>
<li>Un accesso alla memoria = <strong>ĸ</strong> unità di tempo</li>
</ul>
<p>Allora il <strong>tempo effettivo d’accesso</strong> (<em>effective access time</em>):</p>
<p>$$EAT = (ĸ + ε)ɑ + (2ĸ + ε)(1-ɑ) = (2-ɑ)ĸ +ε$$</p>
<p>Dove la prima parte indica il tempo in caso di successo mentre la seconda indica il tempo in caso di insuccesso.</p>
<p>Questo <em>EAT</em> è il <strong>tempo medio che un sistema impiega per accedere alla memoria</strong>, tendendo conto sia degli <strong>hit cache</strong> che dei <strong>miss cache</strong>.</p>
<p>(supponendo che la pagina sia effettivamente presente in memoria fisica, ovvero che non debba esser caricata dalla memoria di massa)</p>
<h4 id="dimensione-della-tabella-delle-pagine"><a class="header" href="#dimensione-della-tabella-delle-pagine">Dimensione della tabella delle pagine</a></h4>
<p>La scelta della dimensione della pagina influenza molto l’efficienza, per questo è necessario che si trovi un gusto compromesso per sistemi general porpose.</p>
<p>Supponendo di avere un sistema che valuta indirizzi a <code>32bit</code>.
→ Lo spazio totale di indirizzamento:  \(2^{32} = 4\)GB.</p>
<p>Usando pagine di \(1\)KB (\(2^{10}\)):</p>
<ul>
<li><strong>dimensione</strong> della tabella: \(2^{22} = 4\)MB → ⚠️​</li>
<li><strong>frammentazione interna</strong> media: \(\frac{2^{10}}{2} = 0.5\)KB → 👍🏿</li>
</ul>
<p>Usando pagine di \(64\)KB (\(2^{16}\)):</p>
<ul>
<li><strong>dimensione</strong> della tabella: \(2^{16} = 64\)KB → 👍🏿</li>
<li><strong>frammentazione interna</strong> media: \(\frac{2^{16}}{2} = 32\)KB → ⚠️​</li>
</ul>
<p>Come si può notare la scelta di una dimensione o del numero di pagine influenza l’altra grandezza.</p>
<p>→ bisogna scegliere una <strong>dimensione di pagina</strong> che abbia un buon <strong>compromesso</strong> tra i due valori.<br>→ Il compromesso è tra <strong>frammentazione e performance</strong>. Perché aumentato il numero di pagine riduco la frammentazione ma diminuisco le performance poiché il SO deve gestire un grande numero di pagine; invece diminuendo il numero di pagine aumento la frammentazione interna media per ogni pagina.</p>
<h3 id="validità-delle-pagine-virtuali"><a class="header" href="#validità-delle-pagine-virtuali">Validità delle pagine virtuali</a></h3>
<p>Raramente un processo usa tutto il suo spazio di indirizzamento virtuale.<br>→ quantità di memoria usata tipicamente da una applicazione desktop si aggira intorno: ~\(100\)MB. (single process)</p>
<p>Lo spazio virtuale che un processo potenzialmente può utilizzare è pari all’intero spazio di indirizzamento: se ho <code>32bit</code> per indirizzo → \(4\)GB</p>
<p align="center"><img src="images/spazio_processi.png" width="300"></p>

<p>In realtà alcune delle pagine all’interno dello spazio virtuale allocato, non sono veramente utilizzate.</p>
<p>→ tra i bit di controllo possiamo aggiungere un <em>validity bit</em>.</p>
<p>Quindi il SO può marcare le pagine <strong>virtuali in uso</strong> usando tale bit nella tabella delle pagine.</p>
<blockquote>
<p>il bit di validità si riferisce alle pagine virtuali → infatti ogni entry point della tabella delle pagine identifica una pagina virtuale.</p>
</blockquote>
<p>Il bit di validità viene attivato nel momento in cui la pagina è <strong>allocata</strong> dal processo (es. tramite <code>malloc()</code>).</p>
<p align="center"><img src="images/bit_validita.png" width="400"></p>

<p>Supponendo che all’interno della page table sono contenute tutte le possibili pagine che un processo può utilizzare. → copre l’intero spazio di indirizzamento.</p>
<p>Allora potremmo avere due casistiche nel momenti in cui un processo genera un indirizzo virtuale la cui parte che <strong>identifica il numero</strong> di pagina non è associato a nessun frame fisico.<br>Le cause di questa situazione sono dovute al fatto che:</p>
<ul>
<li>la pagina potrebbe esser stata swappata V = 0;</li>
<li>l’indirizzo virtuale non appartiene ad alcuna regione di memoria valida del processo.</li>
</ul>
<p align="center"><img src="images/page_fault.png" width="500"></p>

<p>La MMU genera quindi genera una <strong>exception</strong> (page fault).</p>
<ul>
<li>Il SO non termina subito il processo se la pagina appartiene al suo spazio di indirizzamento, infatti viene eseguita l’ISR per gestire il page fault che cerca di allocarla dalla memoria secondaria.
<ul>
<li>Il SO termina il processo solo le il risultato del page fault handler non mappa la pagina virtuale in una pagina fisica → perché non è stata trovata nella memoria secondaria.</li>
<li>Oppure se l’operazione che il processo tenta di fare su tale area non è valida secondo i permessi descritti su questa.</li>
</ul>
</li>
</ul>
<p>Cosa accede durante un <strong>context switch</strong></p>
<p align="center"><img src="images/contex_switch.png" width="500"></p>

<ul>
<li>La TLB viene popolata a <strong>run-time</strong> → inizialmente saranno presenti solo page fault che portano al SO a ricaricare le pagine in memoria principale.</li>
</ul>
<p>Oltre al bit di validità è presente un ulteriore bit di controllo: il <em>dirty bit</em>.</p>
<p>Questo dirty bit è legato al fatto che la pagina <strong>è stata scritta</strong> durante la sua permanenza in memoria fisica.</p>
<p>Quando un processo <strong>scrive</strong> in una pagina fisica, la MMU setta automaticamente il dirty bit a \(1\).<br>Questo bit indica che il contenuto della pagina <strong>non coincide più</strong> con la copia originale presente su disco. → tale informazione ha un implicazione durante lo <strong>swap-out</strong>.</p>
<ul>
<li>Se il dirty bit = 1, significa che la pagina contiene modifiche <strong>che devono essere salvate nello swap</strong>, altrimenti andrebbero perse.</li>
<li>Se il dirty bit = 0, significa che la pagina <strong>non è stata modificata</strong> e che <strong>esiste già una copia valida</strong> della pagina su disco (es. nell’eseguibile del processo, è stata già salvata precedentemente).</li>
</ul>
<p>Per il meccanismo di coerenza caching, si deve garantire la coerenza tra memoria grande e memoria piccola.</p>
<h3 id="struttura-della-tabella-delle-pagine"><a class="header" href="#struttura-della-tabella-delle-pagine">Struttura della tabella delle pagine</a></h3>
<p>Bisogna capire quale struttura sia più adatta a contenere la tabella delle pagine al fine di risolvere diverse problematiche:</p>
<p><strong>Problemi</strong>: le tabelle delle pagine:</p>
<ul>
<li>hanno grosse dimensioni</li>
<li>sono numerose (una per ogni processo)</li>
<li>sono “sparse” (poche pagine valide)</li>
</ul>
<p><strong>Soluzioni</strong>: per ogni problema</p>
<ul>
<li>Paginazione gerarchica → evita il problema della <strong>grandezza</strong></li>
<li>Tabella delle pagine basata su hash → evita il problema della <strong>numerosità</strong></li>
<li>Tabella delle pagine invertita → non si usa più (ideale per vecchi sistemi operativi)<br>→ per evitare il problema della <strong>sparsità</strong></li>
</ul>
<h4 id="paginazione-gerarchica"><a class="header" href="#paginazione-gerarchica">Paginazione gerarchica</a></h4>
<p>Suddivisione della tabella delle pagine in parti più piccole, secondo una <strong>organizzazione <strong>gerarchica</strong></strong>.</p>
<ul>
<li>La MMU divide l’indirizzo di pagina in più parti (\(p_1,p_2)\), tante quanti sono i livelli di gerarchia.</li>
<li>Nella tabella di primo libello, trova l’indirizzo della tabella di secondo livello, e così via.</li>
</ul>
<hr>
<blockquote>
<p>Nota: la MMU <strong>impiega più tempo per attraversare la tabella gerarchica</strong> (aumentano i tempi di accesso).</p>
</blockquote>
<p>Vediamo il motivo di questo tempo aggiuntivo per attraversare la memoria: (2 livelli di gerarchia)</p>
<p>indirizzo virtuale: \((p_1, p_2, offset)\).</p>
<p>Il flusso sarebbe:</p>
<ol>
<li>La MMU accede alla tabella di primo livello e usando \(p_1\) (<strong>accesso a memoria</strong>) ottiene l’indirizzo base della tabella di secondo livello.</li>
<li>La MMU accede alla tabella di secondo livello e usando \(p_2\) (<strong>accesso a memoria</strong>) ottiene il numero di frame corrispondente.</li>
<li>Infine, la MMU accede alla memoria principale nel frame trovaro e utilizza \(offset\) (<strong>accesso a memoria</strong>) per recuperare la casella desiderata.</li>
</ol>
<p>Il motivo dell’aumento del tempo per attraversare la tabella è che la MMU ha bisogno di fare molti <strong>più accessi a memoria fisica</strong> per tradurre un <strong>singolo</strong> <strong>indirizzo</strong> <strong>virtuale</strong>.</p>
<p>Nel caso di paginazione semplice (ad un livello) il numero di accessi totali per operare la traduzione di un indirizzo virtuale è pari a 2.</p>
<ol>
<li>Accesso alla page table</li>
<li>accesso alla memoria fisica</li>
</ol>
<hr>
<p align="center"><img src="images/tabella_gerarchica.png" width="500"></p>

<ul>
<li>Con l’utilizzo di questa struttura si è risolto il problema della grandezza di una tabella delle pagine.</li>
</ul>
<p align="center"><img src="images/struttura_gerarchica.png" width="600"></p>

<ul>
<li>Linux utilizza 4 livelli gerarchici per la tabella delle pagine di ogni processo.</li>
<li>Questa struttura serve <strong>per evitare di allocare una struttura grande quanto tutto lo spazio indirizzabile dal processo</strong>.<br>→ sono presenti delle porzioni (tabelle intermedie) per cui è possibile evitare l’allocazione perché vuote</li>
</ul>
<p>Le singole tabelle sono più piccole rispetto alla tabella non gerarchica.</p>
<p>ESEMPIO DI PAGINAZIONE A DUE LIVELLI:</p>
<p>Nella paginazione gerarchica, il “numero di pagina” nell’indirizzo virtuale viene <strong>a sua volta suddiviso in più parti</strong> (tante quante sono i livelli di gerarchia).</p>
<p align="center"><img src="images/esempio_gerarchia.png" width="400"></p>

<h4 id="tabelle-delle-pagine-basate-su-hash"><a class="header" href="#tabelle-delle-pagine-basate-su-hash">Tabelle delle pagine basate su hash</a></h4>
<p>Le righe della tabella delle pagine sono organizzate utilizzando una <strong>lista concatenata (linked list)</strong>.</p>
<ul>
<li>Si memorizzano esclusivamente le righe per le pagine valide.</li>
<li>Otteniamo quindi un ulteriore <strong>risparmio di memoria</strong>, ma ciò <strong>rallenta la ricerca</strong> (occorre scandire la linked list, ricerca basata sul contenuto).</li>
</ul>
<p>Per ottimizzare i tempi di ricerca, si dividono le righe su <strong>tante liste concatenate</strong> di <strong>piccole dimensioni</strong>.</p>
<ul>
<li>Una funzione di hash è applicata al numero della pagina virtuale.</li>
<li>Gli elementi (entry) con lo <strong>stesso valore della funzione di hash</strong> sono <strong>collocati</strong> nella <strong>stessa</strong> <strong>lista</strong> <strong>concatenata</strong>.</li>
</ul>
<p align="center"><img src="images/hash_page_table.png" width="500"></p>

<ul>
<li>Dopo l’applicazione della funzione di hash sul numero di pagina, che si trovava nell’indirizzo virtuale, si individua una delle \(M\) pagine (liste concatenate).</li>
<li>Dove \(M &lt; N\) perché la funzione di hash procude delle collisioni (\(N\) è il numero di pagine totali).</li>
<li>Dopo aver individuato la lista concatenata si cerca all’interno di questa il numero di pagina che identifica la pagina fisica in cui è mappata la pagina virtuale.</li>
</ul>
<p>Ovviamente in questo approccio la lunghezza delle liste concatenate è contenuto rispetto al caso in cui abbiamo solo una lista concatenata di tutte le pagine associate ad un processo.</p>
<h4 id="tabella-delle-pagine-invertita"><a class="header" href="#tabella-delle-pagine-invertita">Tabella delle pagine invertita</a></h4>
<p>Negli schemi precedenti esiste <strong>una tabella distinta per ogni processo</strong>.</p>
<p>In questo approccio, <strong>tabella delle pagine invertita</strong>, si hanno queste caratteristiche:</p>
<ul>
<li><strong>Una</strong> sola tabella delle pagine <strong>comune a tutti i processi</strong>.</li>
<li>Questa tabella ha un elemento per <strong>ogni pagina fisica</strong>.</li>
<li>Ogni elemento contiene l’indirizzo <strong>virtuale</strong> della pagina memorizzata <strong>in quella locazione fisica</strong>, con informazioni sul processo detentore della pagina.</li>
</ul>
<p align="center"><img src="images/tabella_delle_pagine_invertita.png" width="500"></p>

<p>Una sola è la tabella delle pagine → globale.</p>
<p>Il numero di righe è pari al numero di pagine fisiche (invece che virtuali).</p>
<ul>
<li>
<p>Ogni entry della tabella contiene il PID, del processo che possiede la pagina fisica, e l’indirizzo virtuale di tale pagina.</p>
</li>
<li>
<p>Una volta trovata la riga corrispondente si valuta l’offset rispetto l’indirizzo di base della tabella delle pagine invertita.<br>Tale offset corrisponde alla prima parte dell’indirizzo fisico della pagina in memoria fisica.</p>
<p>Infatti l’ultima operazione è quella di inserire l’offset nella parte dell’indirizzo virtuale in cui è presente il numero di pagina e il PID.</p>
</li>
</ul>
<p>In questo approccio risparmiamo la numerosità delle pagine, oltre al fatto che queste non sono più sparse nella memoria fisica. → si può sfruttare il principio di località.</p>
<h3 id="segmentazione-paginata"><a class="header" href="#segmentazione-paginata">Segmentazione paginata</a></h3>
<p>Utilizzata in Linux.</p>
<p align="center"><img src="images/segmentazione_paginata.png" width="500"></p>

<p>In questa soluzione si utilizza principalmente una paginazione con il supporto hardware.</p>
<p>Ma a livello software si sfruttano tutti i vantaggi della segmentazione:</p>
<ul>
<li>condivisione dei segmenti</li>
<li>granularità fine per l’assegnazione dei permessi → protezione delle aree di memoria</li>
<li>dimensione variabile dei segmenti</li>
</ul>
<p>Questa tabella dei segmenti viene risolta in software, mentre la tabella delle pagine viene risolta in hardware sempre dall’MMU.</p>
<p>La <strong>tabella dei segmenti</strong> è unica <strong>per ogni processo</strong>.<br>La <strong>tabella delle pagine</strong> è unica per <strong>ogni segmento del processo</strong>.</p>
<p>Quindi per ogni segmento avremo una tabella delle pagine in cui sono mappate le pagine virtuali corrispondenti a tale segmento in pagine fisiche.</p>
<p>Quando il processore utilizza un indirizzo virtuale <code>x = &lt;sg, sc&gt;</code>, <code>sg</code> identifica un segmento all’interno della tabella dei segmenti.<br>Una volta ottenuto l’indirizzo base della tabella delle pagine per il segmento identificato precedentemente, viene utilizzata l’altra parte dell’indirizzo virtuale <code>sc</code> per identificare la pagine fisica.</p>
<p>→ si utilizza <code>sc</code> come offset rispetto l’indirizzo base della tabella delle pagine.</p>
<p>A questo punto, ottenuta l’indirizzo base della pagina fisica, si somma a questo l’offset <code>of</code> per ottenere l’indirizzo fisico a cui il processo fa riferimento.</p>
<p>Ovviamente durante tutto questo processo si devono verificare le condizione che non causino inconsistenze tra i processi, come le condizione di limite con <code>STBL</code> e <code>PTLR</code>.</p>
<blockquote>
<p>Quindi nella tabella dei segmenti individuo l’<em>entry point</em> che fa riferimento alla tabella delle pagine per quel segmento.</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><script src="../javascript.js"></script>
<h1 id="gestione-della-memoria-in-linux"><a class="header" href="#gestione-della-memoria-in-linux">Gestione della memoria in Linux</a></h1>
<p>Con l’uso di <code>top</code> possiamo avere info sull’utilizzo di memoria fisica utilizzata e la dimensione degli spazi di indirizzamento di ogni processo.</p>
<p align="center"><img src="images/top.png" width="500"></p>

<ul>
<li>
<p><span style="color: #ff3131; background: #333;"><b>Memoria RAM e SWAP del sistema, il loro utilizzo e la quantità libera</b></span></p>
</li>
<li>
<p><span style="color: #cb6ce6; background: #333;"><b>Spazio di indirizzamento utilizzato dal processo</b></span></p>
</li>
<li>
<p><span style="color: #c1ff72; background: #333;"><b>Memoria “residente”, ovvero lo spazio occupato in RAM dal processo</b></span></p>
</li>
<li>
<p><span style="color: #5ce1e6; background: #333;"><b>Pagine condivise dai processi (es. codice librerie)</b></span></p>
</li>
</ul>
<p>Linux utilizza una gestione della memoria del tipo <strong>paginata</strong> e <strong>segmentata</strong>.</p>
<ul>
<li>Paginazione: la memoria è suddivisa in piccole unità chiamate <em>pagine</em> che possono essere mappate in memoria fisica.</li>
<li>Segmentazione: è una tecnica più vecchia, ma non più utilizzata in modo prevalente nelle versioni moderne, ma offre diversi vantaggi rispetto la paginazione che si intendono sfruttare.</li>
</ul>
<p>Una delle caratteristiche di Linux è la sua <strong>portabilità</strong>, ossia capacità di girare su più architetture diverse. Tale gestione della memoria infatti è fatta per essere compatibile con diverse piattaforme hardware, rendendo il sistema operativo glessibile e adattabile a veri tipi di dispositivi</p>
<p>Infatti tale gestione della memoria è supportata anche per sistemi con grandi quantità di memoria (NUMA) e multi-processore (SMP).</p>
<p>Linux sfrutta la paginazione gerarchica per mantenere le tabelle delle pagine. Questa gerarchia solitamente è su 4 livelli, infatti ogni indirizzo virtuale (o lineare) è suddiviso logicamente in campi ognuno dei quali identificano un offset per la tabella della pagine di un livello.</p>
<p>ESEMPIO DI TRADUZIONE DI UN INDIRIZZO VIRTUALE:</p>
<p align="center"><img src="images/paginazione_gerarchica.png" width="500"></p>

<p>Ogni pagina ha una dimensione fissata che può esser modificata all’atto della compilazione del kernel.</p>
<p>Tipicamente, le due dimensioni possibili in <code>x86</code> sono <code>4KB</code> e <code>4MB</code>. Per Linux di default ogni pagina ha una dimensione di <code>4KB</code>.</p>
<p>Per riferirci alla prima tabella delle pagine che si trova al livello più basso sfruttiamo l’indirizzo virtuale mantenuto all’interno del <em>controll register</em>, che per <code>x86</code> è il register 3.</p>
<p>Questo registro viene popolato all’atto del <strong>context switch</strong>, ogni processo ha associata la propria gerarchia di tabelle di pagine. Essendo una caratteristica direttamente legata al processo, tale indirizzo è contenuto all’interno del descrittore, che in Linux è chiamato <code>task_struct</code>.</p>
<h2 id="spazio-di-indirizzamento-virtuale"><a class="header" href="#spazio-di-indirizzamento-virtuale">Spazio di indirizzamento virtuale</a></h2>
<p>Le nuove versioni di Linux <strong>non si avvalgono del processore per la segmentazione</strong>, ovvero non utilizzano il <strong>meccanismo di segmentazione</strong> fisico implementato dentro la <strong>MMU</strong>.</p>
<p>Per motivi di:</p>
<ul>
<li>portabilità</li>
<li>efficienza del context switch e traduzione degli indirizzi</li>
</ul>
<p align="center"><img src="images/segmentazione_paginata_1.png" width="500"></p>

<!-- @todo capisci perché non è portabile -->
<p>Viene quindi utilizzata una paginzazione segmentata in cui la segmentazione è implementata via software. In modo da sfruttare i vantaggi di questa.</p>
<p>La memoria è organizzata in <strong>Virtual Memory Areas</strong> (<em><strong>VMA</strong></em>) che consiste nell’unità di virtualizzazione della memoria.</p>
<p>Ogni VMA rappresenta un <strong>blocco contiguo</strong> di <strong>memoria</strong> <strong>virtuale</strong> e corrisponde ad un segmento.</p>
<p>Quindi possiamo avere VMA, <strong>ovvero pagine virtuali contigue</strong>, contenenti codice, stack, librerie, … .</p>
<p>Ogni VMA è <strong>tipizzata</strong> per il <strong>contenuto</strong>, come avviene per i segmenti. Inoltre per ognuna possiamo gestire i permessi, per tipologia di pagina.</p>
<p>Quindi possiamo avere una <strong>maggiore granularità</strong> per gestire l’accesso ai blocchi contigue rispetto alla paginazione in cui la granularità era più fine.</p>
<p>Ciò mi permette di proteggere e condividere porzioni dello spazio di indirizzamento in base al suo contenuto.</p>
<h2 id="struttura-di-una-vma"><a class="header" href="#struttura-di-una-vma">Struttura di una VMA</a></h2>
<p>Una VMA è gestida dal kernel mediante una struttura dati che contiene tutte le informazioni necessarie. Il puntatore a tale struttura è contenuto all’interno del descrittore del processo.</p>
<p align="center"><img src="images/mm_struct.png" width="500"></p>

<ul>
<li><code>mm_struct</code> è la struttura del kernel di Linux che rappresenta la <strong>gestione della memoria virtuale di un processo</strong>.</li>
<li>Ogni <code>vm_area_struct</code> rappresenta una Virtual Memory Area. Ognuna ha un insieme di permessi e la posizione nello spazio di memoria virtuale.</li>
<li>Ogni <code>vm_area_struct</code> è associata ad un blocco contiguo di memoria .contenente dati di una specifica categoria.</li>
<li>Inoltre ogni struttura per le VMA punta alla successiva.</li>
</ul>
<p>Le pagine <code>anonymous</code> sono quelle che non sono associate a nessun file esterno, ovvero in memoria di massa. Quindi all’atto della terminazione del processo, il contenuto di tali aree viene perso.</p>
<p>Invece le pagine abbinate ad un file sul disco sono dette <code>memory-mapped</code></p>
<p align="center"><img src="images/mm_struct_1.png" width="500"></p>

<ul>
<li><code>vm_file</code> si riferisce al file presente in memoria di massa, quindi non è contenuto nelle VMA anonime.</li>
<li>All’interno della <code>mm_struct</code>, che rappresenta l’intera memoria virtuale, è presente anche il puntatore alla <strong>page table</strong> che il processo in questione: <code>gpd</code>.</li>
</ul>
<p>ESEMPIO DI SPAZIO VIRTUALE DI UN PROCESSO IN LINUX</p>
<p align="center"><img src="images/Spazio_virtuale_VMA.png" width="400"></p>

<ul>
<li>Ogni VMA ha un range e una tipologia che identifica il contenuto.</li>
<li>Gli indirizzi che vengono utilizzati sono indirizzi lineari o virtuali.</li>
<li>C’è sempre la presenza, per ogni memoria virtuale di un processo, una <strong>porzione riservata al kernel</strong>.</li>
</ul>
<p>Possiamo visualizzare la disposizione delle VMA all’interno della memoria virtuale utilizzando le informazioni contenute all’interno dello pseudo-filesystem <code>proc</code>.</p>
<p>Utilizzando infatti <code>cat /proc/&lt;PID&gt;/maps</code> otteniamo una cosa del genere:</p>
<p align="center"><img src="images/maps_slide.png" width="500"></p>

<ul>
<li>In questo caso non sono presenti VMA condivise tra processi.</li>
<li>Tutti gli indirizzi presenti sono sempre virtuali.</li>
</ul>
<p>Con VMA condivise tra processi:</p>
<p align="center"><img src="images/maps.png" width="600"></p>

<p>Vediamo come possono essere mappate tali pagine virtuali in pagine fisiche in memoria fisica:</p>
<p align="center"><img src="images/pagine_fisiche_e_disco.png" width="500"></p>

<p>Come possiamo vedere le pagine virtuali della VMA <code>/bin/cat</code> nella memoria fisica non sono allocate in maniera contigua.</p>
<p>Inoltre tali pagine sono <code>memory-mapped</code>, quindi è presente una loro copia in memoria di massa.</p>
<p>Lo stesso non si può dire per le pagine fisiche che corrispondono allo <strong>heap</strong> del processo.</p>
<!-- @todo continua... slide 149 -->
<p>// TODO: continua.</p>
<div style="break-before: page; page-break-before: always;"></div><script src="../javascript.js"></script>
<h1 id="virtualizzazione"><a class="header" href="#virtualizzazione">Virtualizzazione</a></h1>
<p>Una macchina <strong>virtuale (VM)</strong> è una emulazione (mediante tecniche sw/hw) di una macchina reale.</p>
<p>Ogni macchina virtuale esegue il proprio <strong>sistema operativo</strong> ed applicazioni.</p>
<p>Le VM sono gestite da una <strong>virtual machine monitor (VMM)</strong>, o <strong>hypervisor</strong>. Più macchine virtuali condividono le risorse fisiche della macchina su cui eseguono.</p>
<p>Su una stessa macchina reale possono coesistere diverse macchine virtuale attive che condividono le risorse di questa.</p>
<h3 id="motivi-che-hanno-portato-allutilizzo-delle-vm"><a class="header" href="#motivi-che-hanno-portato-allutilizzo-delle-vm">Motivi che hanno portato all’utilizzo delle VM</a></h3>
<ul>
<li>Performance</li>
<li>Flessibilità</li>
<li>Affidabilità</li>
<li>Sicurezza</li>
</ul>
<p>Per ottenere queste qualità sarebbe necessario isolare ogni applicazione in modo che una di queste vada in crash le altre non sarebbero influenzate.</p>
<p>Senza VM, il problema sarebbe che per ottenere questo isolamento usando solo hardware fisico, bisognerebbe comprare una macchina fisica per ogni singolo servizio.</p>
<p>Utilizzare tante macchine fisiche quanti sono i servizi oltre ad essere molto costoso è anche uno spreco di energia e spazio.</p>
<p>Utilizzando invece diverse VM, una per ogni servizio da eseguire, possiamo ottenere la caratteristica di isolamento e inoltre si riducono enormemente gli spazi e il costo necessario.</p>
<blockquote>
<p>Questa operazione è detta <strong>consolidation</strong>, ovvero raggruppare più macchine virtuali su un unico server fisico per ottimizzare l’uso delle risorse.</p>
</blockquote>
<h3 id="gestione-di-sistemi-virtualizzati"><a class="header" href="#gestione-di-sistemi-virtualizzati">Gestione di sistemi virtualizzati</a></h3>
<p>Le macchine virtuali possono essere velocemente create, configurate, monitorate, migrate…</p>
<p>Attraverso strumenti software centralizzati.</p>
<h3 id="efficienza"><a class="header" href="#efficienza">Efficienza</a></h3>
<p>Avere più VM su una stessa macchina fisica (<strong>workload consolidation</strong>) permette di sfruttare appieno la capacità dell’hardware e di ridurre i consumi energetici.</p>
<p align="center"><img src="images/efficienza_delle_VM.png" width="500"></p>

<h3 id="flessibilità"><a class="header" href="#flessibilità">Flessibilità</a></h3>
<p>Applicazioni <strong>legacy</strong>, basare su SO obsoleti e non più supportati, possono essere eseguite su macchine moderne.</p>
<p>Quindi questo eviterebbe il problema di continuare ad utilizzare macchine legacy unicamente per la loro compatibilità con l’applicazione che è in esecuzione su esse.</p>
<h3 id="virtualizzazione-e-cloud-computing"><a class="header" href="#virtualizzazione-e-cloud-computing">Virtualizzazione e cloud computing</a></h3>
<p>Il <strong>cloud computing</strong> permette lo outsourcing (spostare) di VM in centri di calcolo privati o di terze parti (<strong>pat-per-use</strong>).</p>
<p>Quindi invece di eseguire le macchine virtuali sui propri server in azienda, il Cloud Computing permette di spostare la loro esecuzione in centri di calcolo. → Non si paga più per l’hardware ma per l’utilizzo di risorse.</p>
<p>Questo riduce il costo della manutenzione e gestione dei server fisici per le aziende.</p>
<h3 id="affidabilità-e-sicurezza"><a class="header" href="#affidabilità-e-sicurezza">Affidabilità e sicurezza</a></h3>
<p>Le macchine virtuali permettono di isolare meglio le applicazioni, questo mi garantisce affidabilità e sicurezza.</p>
<ul>
<li>Un’applicazione compromessa o difettosa opera solo sulla VM isolata, e non può interferire con le altre VM su cui sono eseguiti altri servizi.</li>
<li>Il VMM è l’unico componente <strong>privilegiato</strong> che può gestire l’hardware fisico e le macchine virtuali.</li>
</ul>
<p align="center"><img src="images/safe_VM.png" width="300"></p>

<h2 id="confronto-tra-vmm-e-so"><a class="header" href="#confronto-tra-vmm-e-so">Confronto tra VMM e SO</a></h2>
<p>Il VMM, come il SO, fornisce una <strong>astrazione</strong> della macchina fisica su cui esegue</p>
<p>Il SO è già di per se un virtualizzatore dell’hardware (di risorse):</p>
<ul>
<li>concetto di processo</li>
<li>concetto di file e directory attraverso il FS</li>
<li>concetto di memoria virtuale</li>
<li>socket</li>
<li>…</li>
</ul>
<p>“Container (Fine slide)”</p>
<p>L’astrazione offerta dal SO non è in senso stretto, perché quello che fa effettivamente un virtual machine monitor è quello di emulare completamente l’intera architettura virtuale su un’architettura fisica del tutto diversa.</p>
<p>Posso emulare un’architettura <code>arm</code> su una intel <code>x86</code> senza problemi, per il tipo di astrazione offerta da un VMM.</p>
<p align="center"><img src="images/confronto_SO_VMM.png" width="500"></p>

<h2 id="architetture-principali-di-una-hypervisor"><a class="header" href="#architetture-principali-di-una-hypervisor">Architetture principali di una hypervisor</a></h2>
<ul>
<li>TIPO 1</li>
<li>TIPO 2</li>
</ul>
<ol>
<li>
<p>Il VMM esegue su un “hardware nudo” (<strong>bare-metal virtualization</strong> o <strong>server virtualization</strong>).</p>
<p>In questa architettura, il software di virtualizzazione è il padrone dell’hardware assoluto.</p>
<p>Questo tipo di hypervisor viene molto utilizzato nei data center.</p>
<p>L’architettura di tipo 1 ha migliori prestazioni perché non c’è un ulteriore layer (livello di indirezione) che divide il VMM dall’hardware, a differenza di ciò che accade nell’architettura di tipo 2</p>
<p align="center"><img src="images/architettura1.png" width="300"></p>

</li>
<li>
<p>Il VMM esegue su un SO tradizionale (es. Windows), viene detta <strong>hosted hypervisor</strong>.</p>
<p>Per comunicare con l’hardware il sistema operativo <strong>guest</strong> deve passare per l’hypervisor che a sua volta deve passare per il sistema operativo <strong>host</strong>.</p>
<p>L’hypervisor è considerato per il SO host come un qualsiasi altro processo in esecuzione.</p>
<p>Questo utilizzo facilita l’integrazione tra sistemi operativi, ad esempio, posso copiare file facilmente dal desktop dell’host dentro la macchina virtuale guest.</p>
<p>Ha come svantaggio le performance perché ogni richiesta della VM deve attraversare due strati: l’Hypervisor e poi il sistema operativo host.</p>
<p>Consiste nell’architettura che utilizziamo con VMware Workstation/Fusion, Oracle VM VirtualBox.</p>
</li>
</ol>
<p>In generale un hypervisor deve garantire di virtualizzare:</p>
<ul>
<li>la CPU</li>
<li>la memoria</li>
<li>l’I/O</li>
</ul>
<h2 id="virtualizzazione-della-cpu"><a class="header" href="#virtualizzazione-della-cpu">Virtualizzazione della CPU</a></h2>
<p>Le prime tecniche di virtualizzazione della CPU consistono nel far credere al kernel della macchina virtuale guest che il <strong>processore virtuale</strong> su cui opera <strong>sia fisico</strong>.</p>
<p>L’hypervisor deve quindi implementare un mapping 1:1 tra il processore da emulare e quello fisico su cui effettivamente viene eseguito il kernel guest.</p>
<p>Tutto quello che viene eseguito in kernel mode nel guest in realtà non è un vero e proprio kernel mode; in realtà è in user mode rispetto al sistema operativo host.</p>
<p>Quindi se per il sistema operativo host la macchina virtuale non è altro che un semplice processo, deve essere l’hypervisot ad astrarre completamente un macchina fisica per il kernel guest.</p>
<p>L’hypervisor deve quindi intercettare delle “istruzioni critiche” (<strong>sensitive instructions</strong>)</p>
<p align="center"><img src="images/istruzioni_critiche.png" width="500"></p>

<p>L’hypervisor deve intercettare le istruzioni critiche che necessitano di un grado di privilegio superiore che la VM non ha. C’è la necessità di emulare questa istruzione.</p>
<h3 id="de-privileging"><a class="header" href="#de-privileging">De-privileging</a></h3>
<p>Primo meccanismo che deve essere implementato all’interno degli hypervisor.</p>
<p>Tale concetto consiste nel “degradare” o togliere i privilegi al SO ospite, spostandolo a un livello di esecuzione inferiore rispetto a quello a cui è abituato a girare, ovvero spostarlo in user mode.</p>
<ul>
<li>La VMM (hypervisor) gira nel vero <strong>kernel</strong> <strong>mode</strong>. È l’unico che ha il controllo diretto e privilegiato dell’hardware fisico</li>
<li>Il guest SO viene spostato in <strong>user mode</strong> completamente. Quindi quanto il guest SO pensa di operare in kernel mode in realtà di trova ancora in user mode, e chiamiamo questo livello di privilegio <strong>virtual kernel mode</strong></li>
</ul>
<p>Ovvero:</p>
<ul>
<li>VMM → kernel mode</li>
<li>VM → user mode, dentro cui:
<ul>
<li>→ guest SO è in virtual kernel mode</li>
<li>→ i processi del guest SO sono in virtual user mode</li>
</ul>
</li>
</ul>
<p align="center"><img src="images/virtual_mode.png" width="500"></p>

<p>Per permettere al guest SO di operare in kernel mode, un primo meccanismo che si può sfruttare è quello delle trap: nel momento in cui il guest esegue delle istruzioni privilegiate/critiche, allora la CPU virtuale genera una <strong>trap</strong>.</p>
<p>Questo meccanismo è detto: <strong>TRAP-AND-EMULATE</strong>.</p>
<p>Questa trap viene intercettata dall’hypervisor, elabora il tipo di istruzione che ha generato quella trap ed emula l’istruzione privilegiata associata.</p>
<p>Tutte le istruzioni sensitive non possono eseguire direttamente, ma devono passare per l’hypervisor, e vengono a scatenare una trap → passa il controllo (de-privilegin) all’hypervisor che emula/simula l’effetto dell’istruzione.</p>
<p align="center"><img src="images/intercettazione_trap.png" width="500"></p>

<p>Nel caso di CPU intel questa cosa avviene in maniera diversa, perché in queste CPU esistono diversi livelli di privilegio, classificati in Ring.</p>
<p>4 livelli di privilegio, dove Ring 3 ha il più basso livello di privilegio mentre in Ring 0 la VMM.</p>
<p>Cosa accade quando il guest SO vuole eseguire una istruzione sensitive:</p>
<p align="center"><img src="images/sensitive_inst_inte.png" width="400"></p>

<ul>
<li>L’applicazione che gira nella VM esegue una system call, questo causa una trap della CPU virtuale che viene gestita dalla VMM. La VMM salta al guest host per far eseguire l’interrupt handler e poi la ISR associata alla trap generata.</li>
<li>L’interrupt hardware invece sono gestite dalla VMM che eseguono l’ISR e successivamente si salta all’esecuzione dell’ISR del guest SO.</li>
<li>Invece le istruzioni privilegiate nel guest SO causano il generarsi di una trap che viene intercettata dalla VMM che la gestisce ed emula l’effetto desiderato dal guest SO.</li>
</ul>
<hr>
<p>Poniamo in esempio che il guest SO voglia eseguire una <code>CLI</code>.</p>
<p>Il VMM simula la <code>CLI</code> ponendo a <code>0</code> lo <em><strong>Interrupt Flag</strong></em> all’interno di una struttura dati dedicata alla VM.</p>
<ul>
<li>Lo <em>Interrupt Flag</em> nel <strong>registro fisico</strong> della CPU è inalterato</li>
<li>Le interrupt fisiche sono ancora ricevute dallo VMM</li>
</ul>
<p>La VMM emula l’effetto della chiamata di sistema, infatti da quel momento in poi la VMM continuerà a ricevere delle interruzioni dalla CPU fisica, ma non le inoltra al guest SO.</p>
<h3 id="problemi-con-larchitettura-x86"><a class="header" href="#problemi-con-larchitettura-x86">Problemi con l’architettura <code>x86</code></a></h3>
<p>L’architettura <code>x86</code> tradizionale <strong>non è</strong> <strong>“virtualizzabile”</strong> con solo il trap-and-emulate.</p>
<p>Il motivo è che molte delle istruzioni sensibili <strong>non generano alcuna trap</strong></p>
<p>Quindi non è più sufficiente il meccanismo di trap-and-emulate.</p>
<p>Se il guest tenta di eseguire una istruzione sensitive, la CPU <strong>ignora l’istruzione</strong>; tali istruzioni sono dette <strong>“sensibili ma non privilegiate”</strong>.</p>
<p>Questo è stato risolto grazie ad un supporto hardware, cioè sono state introdotte delle istruzioni specifiche per la virtualizzazione.</p>
<p>Ma prima di ciò non era possibile virtualizzare tale architettura.</p>
<!-- @todo metti il teorema in un quadretto carino -->
<ul>
<li>
<p>Teorema di Popek e Goldberg</p>
<p>Una macchina può essere virtualizzata se ogni istruzione sensitive è privilegiata.</p>
<p>Le istruzioni privilegiate sono quelle che scatenano una <em>trap</em> quando eseguite in user mode.</p>
<p>Invece un’istruzione è definita sensitive quanto interagisce direttamente con la configurazione o lo stato dell’hardware sottostante.</p>
</li>
</ul>
<h3 id="tecniche-della-virtualizzazione-delle-cpu"><a class="header" href="#tecniche-della-virtualizzazione-delle-cpu">Tecniche della virtualizzazione delle CPU</a></h3>
<ul>
<li>
<p><strong>Full virtualization</strong>, senza supporto hardware</p>
<p>Utilizza tecniche software complesse come la <strong>Dynamic Binary Traslation</strong>. Il VMM legge il binario del Guest SO e lo “riscrive” al volo per renderlo sicuro, senza che il guest SO se ne accorga.</p>
</li>
<li>
<p><strong>Para-virtualization</strong></p>
<p>il guest SO è sviluppato appositamente per cooperare con il VMM.</p>
<p>Si abbandona l’idea di ingannare il guest SO, è consapevole di essere su una macchina virtuale. Il SO ospite viene riscritto per essere consapevole di girare su una macchina virtuale, quindi invece di provare ad eseguire istruzioni hardware direttamente si interfaccia con la VMM (cooperazione).</p>
</li>
<li>
<p><strong>Full virtualization</strong>, con <strong>supporto hardware</strong></p>
<p>migliori prestazioni e VMM più semplice.</p>
<p>La CPU stessa ha nuove modalità che permettono al VMM di intercettare le operazioni critiche senza dover riscrivere il codice software.</p>
</li>
</ul>
<hr>
<p>ESEMPIO: confronto tra <strong>para-virtualization</strong> e <strong>full</strong> <strong>virtualization</strong></p>
<p>Il problema da risolvere è lo stesso: il guest SO vuole leggere un registro critico, quello contenente l’indirizzo della <strong>Interrupt Descriptor table</strong>.</p>
<p>Queste due soluzioni ci permettono di farlo ma con approcci differenti:</p>
<ul>
<li>
<p><strong>Dynamic</strong> <strong>Binary</strong> <strong>Traslation</strong></p>
<p>Agisce sul <strong>codice binario</strong>.</p>
<p>Il sorgente del sistema operativo non viene toccato, quindi si può utilizzare un qualsiasi sistema operativo, anche Windows.</p>
<p>Il VMM analizza il flusso di istruzioni mentre vengono eseguite, intercettando quelle sensitive.</p>
<p>Infatti quando vede <code>mov val, idtr</code>, la intercetta e la sostituisce dinamicamente con una chiamata alla sua funzione che emula l’effetto di quella istruzione.</p>
</li>
<li>
<p><strong>Hypercall</strong></p>
<p>Si agisce sul <strong>codice sorgente</strong>. Gli sviluppatori del sistema operativo modificano il codice: cancellando istruzioni problematiche e inserendo una chiamata esplicita alla VMM, chiamata <strong>Hypercall</strong>.</p>
<p>È una soluzione molto efficiente, ma richiede di poter modificare il codice sorgente del SO e ricompilarlo. (impossibile con Windows)</p>
</li>
</ul>
<p>Quindi consideriamo di trovarci in questa situazione:</p>
<p align="center"><img src="images/full-para-virtual.png" width="400"></p>

<ul>
<li>Codice sorgente</li>
<li>Codice binario che viene eseguito</li>
<li>funzione del VMM che emula il comportamento dell’istruzione in esame</li>
</ul>
<p>Per l’approccio che utilizza la para-virtualization il sorgente deve essere modificato per poter girare su una VM. La modifica consiste nella chiamata alla funzione dal VMM che emula quel comportamento, ovvero <code>emulate_store_idt()</code> (Hypercall).</p>
<p>Per l’approccio che utilizza la full virtualization il sorgente rimane invariato, e a tempo di esecuzione abbiamo due principali tecniche che dipendono dalla presenza o meno del supporto hardware.</p>
<ul>
<li>Meccanismo software (Dynamic Binary Traslation): la VMM sostituisce dinamicamente le istruzioni. Il VMM legge il <strong>codice binario</strong> prima che venga eseguito, individua le istruzioni critiche e le riscrive sostituendole con il codice di emulazione → <code>emulate_store_idt()</code>.</li>
<li>Meccanismo hardware (Intel VT-x / Trap-and-Emulate): in questo caso il codice binario in memoria non viene necessariamente sostituito/riscritto. È la CPU fisica che, quando incontra l’istruzione critica mentre gira la VM (in <em>non-root mode</em>), ferma tutto e genera un evento hardware (<strong>VMExit</strong>). Il controllo passa al VMM che esegue l’emulazione e poi restituisce il controllo.</li>
</ul>
<p align="center"><img src="images/risoluzione_DBT_e_HYPERCALL.png" width="470"></p>

<h4 id="full-virtualization-no-supporto-hw"><a class="header" href="#full-virtualization-no-supporto-hw">Full virtualization, no supporto hw</a></h4>
<p>Nel caso di una CPU fisica che non supporta la virtualizzazione, in cui non tutte le istruzioni sensitive generano una trap, l’hypervisor di <strong>VMware</strong> introdusse tecniche efficienti di full-virtualization per Intel <code>x86</code>.</p>
<p>Queste tecniche sono ad esempio la <strong>Dynamic Binary Traslation</strong>.</p>
<p>Il codice binario del guest veniva riscritto dinamicamente dall’hypervisor prima di essere eseguito: sostituendo le istruzioni sensibili con un codice di emulazione</p>
<p>Coprendo il gap della non virtualizzabilità di <code>x86</code>.</p>
<p>Oggi con il supporto hardware VMware si è adattata perché è molto più performante.</p>
<h4 id="dynamic-binary-traslation"><a class="header" href="#dynamic-binary-traslation">Dynamic Binary Traslation</a></h4>
<p>All’avvio della VM, il VMM analizza a blocchi il codice eseguito dal guest SO.</p>
<p>Ogni blocco, detto <strong>Basic Block</strong> è una breve <strong>sequenza di istruzioni sequenziali</strong> che terminano con una <strong>istruzione di salto</strong>.</p>
<p align="center"><img src="images/basic_block.png" width="180"></p>

<p>L’Hypervisor quindi va a scandire questi blocchi all’interno del binario del kernel e li analizza e riscrive eventuali istruzioni sensitive.</p>
<p>Il salto finale viene sostituito con una chiamata all’hypervisor per mantenere la catena di traduzioni attiva:</p>
<ul>
<li>La CPU esegue il blocco tradotto (sicuro)</li>
<li>Arriva all’ultima istruzione (salto modificato)</li>
<li>Il controllo passa al VMM</li>
<li>Il VMM controlla se il blocco a cui avrebbe saltato la CPU prima della modifica del salto sia già tradotto
<ul>
<li>Se <strong>si</strong>: fa saltare la CPU direttamente alla versione già tradotta e sicura</li>
<li>Se <strong>no</strong>: traduce il nuovo blocco, lo salva in memoria cache, e poi fa saltare la CPU lì</li>
</ul>
</li>
</ul>
<p>In poche parole, il salto finale viene modificato per garantire che la CPU non esegua mai codice originale, ma rimbalzi sempre attraverso il VMM per ottenere il prossimo pezzo di codice tradotto e sicuro.</p>
<p>Vediamo cosa come accade tutto ciò:</p>
<p align="center"><img src="images/DBT_1.png" width="300"></p>

<ul>
<li>Codice grezzo che non è stato ancora tradotto dal VMM</li>
</ul>
<p align="center"><img src="images/DBT_2.png" width="400"></p>

<ul>
<li>Il VMM legge il basic block e lo modifica</li>
</ul>
<p align="center"><img src="images/DBT_3.png" width="400"></p>

<ul>
<li>Dopo la modifica nel basic block viene sostituita l’istruzione sensitive e viene modificato il salto finale per poter permettere al VMM di analizzare il basic block successivo</li>
</ul>
<p align="center"><img src="images/DBT_4.png" width="400"></p>

<ul>
<li>Il controllo viene ripristinato al guest SO così che possa eseguire il codice tradotto e sicuro</li>
<li>Una volta terminata l’esecuzione del blocco l’istruzione di salto riporta il controllo al VMM per continuare con il meccanismo di Dynamic Binary Translation</li>
</ul>
<h4 id="para-virtualizzazione"><a class="header" href="#para-virtualizzazione">Para-virtualizzazione</a></h4>
<p>Con questo approccio c’è la necessità di riscrivere il codice sorgente del guest SO in modo che questo cooperi con il VMM.</p>
<p>Il guest SO è conscio del fatto di esser eseguito su di una macchina virtuale (VM).</p>
<ul>
<li>Le istruzioni sensitive nel guest SO sono sostituite da <strong>hypercalls</strong> che fanno riferimento a funzioni del VMM che emulano il comportamento delle istruzioni originarie.</li>
</ul>
<blockquote>
<p>A differenza della full virtualization, si modifica il <strong>codice</strong> <strong>sorgente</strong> <strong>del</strong> <strong>guest</strong> <strong>SO</strong>, non il codice binario.</p>
<p>La modifica è fatta dal <strong>programmatore</strong> e non dal VMM, quindi i sistemi che possono girare su Hypervisor, che sfruttano questa tecnica di virtualizzazione della CPU, devono essere costruiti ad hoc.</p>
</blockquote>
<p align="center"><img src="images/para_virt.png" width="500"></p>

<p>Il guest SO così modificato <strong>non può eseguire sull’hardware fisico</strong>: può eseguire solo in combinazione con il <strong>VMM</strong>.</p>
<p>Inoltre questo approccio non è utilizzabile per sistemi <strong>legacy</strong> oppure <strong>proprietari</strong>, come Windows.</p>
<h4 id="supporto-hardware-per-la-full-virtualization-della-cpu"><a class="header" href="#supporto-hardware-per-la-full-virtualization-della-cpu">Supporto hardware per la full-virtualization della CPU</a></h4>
<p>Le CPU Intel VT introducono:</p>
<ul>
<li>due modalità di esecuzione: <strong>VMX root</strong> e <strong>VMX non-root</strong>;</li>
<li><strong>VMCS</strong> (VM Control Structure).</li>
</ul>
<p>Queste soluzioni sono implementate nell’hardware per evitare tutto l’overhead dovuto alla traduzione dinamica del codice binario e per permettere a qualsiasi guest SO di poter eseguire su una VM.</p>
<p>Hanno come vantaggio:</p>
<ul>
<li>semplificano il codice del VMM, buona parte della virtualizzazione è fatta in hardware;</li>
<li>evita il <strong>ring de-privileging</strong> del guest SO;</li>
<li>maggiore <strong>efficienza del cambio di contesto</strong> tra VM e VMM;</li>
<li>garantisce il meccanismo di trap per tutte le istruzioni critiche</li>
</ul>
<p>Quindi le principali novità sono:</p>
<ul>
<li>
<p>Modalità di esecuzione (VMX)</p>
<ul>
<li><strong>VMX Root Mode</strong>: dove gira il VMM. Qui il software ha pieno controllo dell’hardware, esattamente come il kernel di un sistema operativo tradizionale.</li>
<li><strong>VMX Non-Root Mode</strong>: dove gira il Guest SO. In questa modalità, il sistema operativo ospite può girare al suo livello di privilegio “naturale” senza dover essere de-privilegiato. Quindi viene eseguito con il massimo dei privilegi ma in VMX non-root mode.</li>
</ul>
</li>
<li>
<p>Passaggio tra Root mode de Non-Root mode</p>
<p>Il passaggio tra queste due modalità è gestito direttamente dall’hardware tramite eventi specifici:</p>
<ul>
<li>
<p><strong>VM Entry</strong>: il passaggio dal VMM al Guest SO. Avviene quando il VMM lancia o riprende l’esecuzione di una VM.</p>
</li>
<li>
<p><strong>VM Exit</strong>: il passaggio inverso, dal Guest SO al VMM. Avviene automaticamente quando il Guest SO tenta di eseguire un’istruzione sensitive (Perché nonostante ha tutti i privilegi, si trova in VMX Non-Root mode).</p>
<p>L’hardware intercetta l’istruzione e restituisce il controllo al VMM affichè possa gestirla.</p>
</li>
</ul>
</li>
<li>
<p><strong>VMCS (Virtual Machiene Control structure)</strong></p>
<p>Per gestire questi passaggi in modo efficiente, intel ha introdotto una struttura dati hardware chiamata <strong>VMCS</strong>. La VMCS agisce coem una “scheda cliente” per ogni VM e contiene:</p>
<ul>
<li><strong>Guest state</strong>: lo stato della CPU quando gira la VM. Viene caricato durante la <em>VM Entry</em> e salvato durante la <em>VM Exit</em>.</li>
<li><strong>Host state</strong>: lo stato della CPU quando gira il VMM. Viene caricato durante la <em>VM Exit</em>.</li>
<li><strong>Control Data</strong>: istruzioni per la CPU fisica su quali eventi devono causare un <em>VM Exit</em></li>
</ul>
</li>
</ul>
<p>Eventi che possono causare <strong>VM Exit</strong>:</p>
<ul>
<li><strong>Istruzioni sensitive</strong>
<ul>
<li>CPUID</li>
<li>RDMSR. WRMSR</li>
<li>INVLPG</li>
<li>RDPMC, RDTSC</li>
<li>HTL, MWAIT, PAUSE</li>
<li>VMCALL: nuova istruzione per invocare il VMM</li>
</ul>
</li>
<li><strong>Accessi a stato sensitive</strong>
<ul>
<li>MOV DRx: accessi ai debug register</li>
<li>MOV CRx: accessi ai control register</li>
<li>Task switch: accessi al CR3 (puntatore alla tabella delle pagine)</li>
</ul>
</li>
<li><strong>Eccezioni ed eventi asincroni</strong>
<ul>
<li>Page fault, debug exceptions, interrupts, etc.</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><script src="../javascript.js"></script>
<h1 id="definizioni-utili"><a class="header" href="#definizioni-utili">Definizioni utili</a></h1>
<ul>
<li>
<p><em><strong>Processo</strong></em>:</p>
<p>Unità base di esecuzione del SO, descrive <strong>l’attività dell’elaboratore relative alla specifica esecuzione di un codice</strong>.</p>
<p>è un’entità dinamica che consiste in: programma da eseguire + stato di esecuzione.</p>
<p>Possiamo avere più processi relativi all’esecuzione di più istanze dello stesso programma.</p>
</li>
<li>
<p><em><strong>Programma</strong></em></p>
<p>Sequenza statica di esecuzione, corrisponde alla codifica in un linguaggio di programmazione comprensibile all’elaboratore, in modo che questo possa essere eseguito.</p>
</li>
<li>
<p><em><strong>Immagine di un processo</strong></em></p>
<p>L’immagine di un processo consiste nell’insieme del codice, area dati globale, stack, heap e il descrittore. Ovvero tutte quelle componenti necessarie all’esecuzione in un contesto di sistema operativo multiprogrammato.</p>
<ul>
<li>Stack</li>
<li>Heap</li>
<li>Area dati globali</li>
<li>Codice → rientrante</li>
<li>PCB</li>
<li>Stack del kernel → utilizzato dal kernel quando il processo esegue in kernel mode</li>
</ul>
</li>
<li>
<p><em><strong>Spazio di indirizzamento</strong></em></p>
<p>L’immagine del processo e le risorse da esso possedute costituiscono il suo spazio di indirizzamento.</p>
</li>
<li>
<p><em><strong>Thread</strong></em></p>
<p>Flusso di controllo sequenziale di un processo eseguito in maniera concorrente a questo.</p>
<p>A differenza di un processo non possiede delle risorse private alla sua esecuzione ma le condivide con altri thread dello stesso processo e il processo stesso.</p>
<p>Quello che appartiene ad un thread - processo leggero - sono:</p>
<ul>
<li>insieme di registri</li>
<li>stack</li>
</ul>
<p>Tutte le altre aree di memoria fanno parte dello spazio di indirizzamento del processo, quindi condivise.</p>
</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <template id=fa-eye><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M288 32c-80.8 0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7 0 24.6C17.3 304 48.6 356 95.4 399.4C142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144s64.5-144 144-144s144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64c-11.5 0-22.3-3-31.6-8.4c-.2 2.8-.4 5.5-.4 8.4c0 53 43 96 96 96s96-43 96-96s-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6z"/></svg></span></template>
        <template id=fa-eye-slash><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M38.8 5.1C28.4-3.1 13.3-1.2 5.1 9.2S-1.2 34.7 9.2 42.9l592 464c10.4 8.2 25.5 6.3 33.7-4.1s6.3-25.5-4.1-33.7L525.6 386.7c39.6-40.6 66.4-86.1 79.9-118.4c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C465.5 68.8 400.8 32 320 32c-68.2 0-125 26.3-169.3 60.8L38.8 5.1zM223.1 149.5C248.6 126.2 282.7 112 320 112c79.5 0 144 64.5 144 144c0 24.9-6.3 48.3-17.4 68.7L408 294.5c5.2-11.8 8-24.8 8-38.5c0-53-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6c0 10.2-2.4 19.8-6.6 28.3l-90.3-70.8zm223.1 298L373 389.9c-16.4 6.5-34.3 10.1-53 10.1c-79.5 0-144-64.5-144-144c0-6.9 .5-13.6 1.4-20.2L83.1 161.5C60.3 191.2 44 220.8 34.5 243.7c-3.3 7.9-3.3 16.7 0 24.6c14.9 35.7 46.2 87.7 93 131.1C174.5 443.2 239.2 480 320 480c47.8 0 89.9-12.9 126.2-32.5z"/></svg></span></template>
        <template id=fa-copy><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M502.6 70.63l-61.25-61.25C435.4 3.371 427.2 0 418.7 0H255.1c-35.35 0-64 28.66-64 64l.0195 256C192 355.4 220.7 384 256 384h192c35.2 0 64-28.8 64-64V93.25C512 84.77 508.6 76.63 502.6 70.63zM464 320c0 8.836-7.164 16-16 16H255.1c-8.838 0-16-7.164-16-16L239.1 64.13c0-8.836 7.164-16 16-16h128L384 96c0 17.67 14.33 32 32 32h47.1V320zM272 448c0 8.836-7.164 16-16 16H63.1c-8.838 0-16-7.164-16-16L47.98 192.1c0-8.836 7.164-16 16-16H160V128H63.99c-35.35 0-64 28.65-64 64l.0098 256C.002 483.3 28.66 512 64 512h192c35.2 0 64-28.8 64-64v-32h-47.1L272 448z"/></svg></span></template>
        <template id=fa-play><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M73 39c-14.8-9.1-33.4-9.4-48.5-.9S0 62.6 0 80V432c0 17.4 9.4 33.4 24.5 41.9s33.7 8.1 48.5-.9L361 297c14.3-8.7 23-24.2 23-41s-8.7-32.2-23-41L73 39z"/></svg></span></template>
        <template id=fa-clock-rotate-left><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M75 75L41 41C25.9 25.9 0 36.6 0 57.9V168c0 13.3 10.7 24 24 24H134.1c21.4 0 32.1-25.9 17-41l-30.8-30.8C155 85.5 203 64 256 64c106 0 192 86 192 192s-86 192-192 192c-40.8 0-78.6-12.7-109.7-34.4c-14.5-10.1-34.4-6.6-44.6 7.9s-6.6 34.4 7.9 44.6C151.2 495 201.7 512 256 512c141.4 0 256-114.6 256-256S397.4 0 256 0C185.3 0 121.3 28.7 75 75zm181 53c-13.3 0-24 10.7-24 24V256c0 6.4 2.5 12.5 7 17l72 72c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-65-65V152c0-13.3-10.7-24-24-24z"/></svg></span></template>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr-ef4e11c1.min.js"></script>
        <script src="mark-09e88c2c.min.js"></script>
        <script src="searcher-c2a407aa.js"></script>

        <script src="clipboard-1626706a.min.js"></script>
        <script src="highlight-abc7f01d.js"></script>
        <script src="book-a0b12cfe.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>


    </div>
    </body>
</html>
